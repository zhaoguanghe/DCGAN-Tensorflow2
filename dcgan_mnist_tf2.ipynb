{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.0.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('tf: {0}'.format(tf.__version__))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()      # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu,bias_initializer=tf.zeros_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.sigmoid)\n",
    "        \n",
    "    def call(self,input):                            # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(input)                      # [batch_size, 784]\n",
    "        x = self.dense1(x)                           # [batch_size, 128]\n",
    "        x = self.dense2(x)                           # [batch_size, 1]\n",
    "        return x\n",
    "    \n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1  = tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu)\n",
    "        self.dense2  = tf.keras.layers.Dense(units=784, activation=tf.keras.activations.sigmoid)\n",
    "        self.reshape =  tf.keras.layers.Reshape(target_shape=(28, 28, 1))\n",
    "        \n",
    "    def call(self,input):         # [batch_size, 100]\n",
    "        x = self.dense1(input)    # [batch_size, 128]\n",
    "        x = self.dense2(x)        # [batch_size, 784]\n",
    "        x = self.reshape(x)       # [batch_size, 28, 28, 1]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x996f208148>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "generator = Generator()#make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.6308204]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()#make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    # Produce images for the GIF as we go\\n    display.clear_output(wait=True)\\n    generate_and_save_images(generator, epoch + 1, seed)\\n\\n    # Save the model every 15 epochs\\n    if (epoch + 1) % 15 == 0:\\n        checkpoint.save(file_prefix = checkpoint_prefix)\\n\\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\\n\\n  # Generate after the final epoch\\n  display.clear_output(wait=True)\\n  generate_and_save_images(generator, epochs, seed)\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(dataset, epochs):\n",
    "    #for epoch in range(epochs):\n",
    "        #start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for i,image_batch in enumerate(dataset):\n",
    "            g,d = train_step(image_batch)\n",
    "            print(\"batch %d, gen_loss %f,disc_loss %f\" % (i, g.numpy(),d.numpy()))\n",
    "\n",
    "'''\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator, epochs, seed)\n",
    "'''\n",
    "\n",
    "def other():\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, gen_loss 0.902442,disc_loss 1.208091\n",
      "batch 1, gen_loss 0.925489,disc_loss 1.138894\n",
      "batch 2, gen_loss 0.997722,disc_loss 1.095758\n",
      "batch 3, gen_loss 0.962782,disc_loss 1.105824\n",
      "batch 4, gen_loss 0.882296,disc_loss 1.176620\n",
      "batch 5, gen_loss 0.875340,disc_loss 1.161040\n",
      "batch 6, gen_loss 0.908787,disc_loss 1.064392\n",
      "batch 7, gen_loss 0.919660,disc_loss 1.141892\n",
      "batch 8, gen_loss 0.973278,disc_loss 1.111685\n",
      "batch 9, gen_loss 1.050881,disc_loss 1.153429\n",
      "batch 10, gen_loss 0.968966,disc_loss 1.122620\n",
      "batch 11, gen_loss 0.977007,disc_loss 1.125437\n",
      "batch 12, gen_loss 0.915537,disc_loss 1.116558\n",
      "batch 13, gen_loss 0.911294,disc_loss 1.140381\n",
      "batch 14, gen_loss 0.924497,disc_loss 1.140242\n",
      "batch 15, gen_loss 0.924846,disc_loss 1.126991\n",
      "batch 16, gen_loss 0.968786,disc_loss 1.095679\n",
      "batch 17, gen_loss 1.020759,disc_loss 1.115838\n",
      "batch 18, gen_loss 1.042583,disc_loss 1.064072\n",
      "batch 19, gen_loss 1.018838,disc_loss 1.049722\n",
      "batch 20, gen_loss 1.024575,disc_loss 1.053359\n",
      "batch 21, gen_loss 1.062516,disc_loss 1.064197\n",
      "batch 22, gen_loss 1.000165,disc_loss 1.045471\n",
      "batch 23, gen_loss 0.983639,disc_loss 1.052741\n",
      "batch 24, gen_loss 1.029430,disc_loss 1.012672\n",
      "batch 25, gen_loss 1.066126,disc_loss 1.048342\n",
      "batch 26, gen_loss 1.049649,disc_loss 1.023120\n",
      "batch 27, gen_loss 1.062911,disc_loss 1.019390\n",
      "batch 28, gen_loss 1.034899,disc_loss 1.025142\n",
      "batch 29, gen_loss 1.025994,disc_loss 0.993211\n",
      "batch 30, gen_loss 1.031506,disc_loss 0.986273\n",
      "batch 31, gen_loss 1.072446,disc_loss 0.988115\n",
      "batch 32, gen_loss 1.048340,disc_loss 1.034353\n",
      "batch 33, gen_loss 1.142182,disc_loss 1.001678\n",
      "batch 34, gen_loss 1.089806,disc_loss 1.003041\n",
      "batch 35, gen_loss 1.066146,disc_loss 1.058448\n",
      "batch 36, gen_loss 1.018708,disc_loss 1.002743\n",
      "batch 37, gen_loss 0.957998,disc_loss 1.079350\n",
      "batch 38, gen_loss 1.018413,disc_loss 1.018489\n",
      "batch 39, gen_loss 1.061439,disc_loss 1.003561\n",
      "batch 40, gen_loss 1.026650,disc_loss 1.066751\n",
      "batch 41, gen_loss 1.035002,disc_loss 1.100663\n",
      "batch 42, gen_loss 1.076816,disc_loss 1.056447\n",
      "batch 43, gen_loss 1.025363,disc_loss 1.104429\n",
      "batch 44, gen_loss 0.943653,disc_loss 1.109075\n",
      "batch 45, gen_loss 0.899430,disc_loss 1.106207\n",
      "batch 46, gen_loss 0.931170,disc_loss 1.112484\n",
      "batch 47, gen_loss 0.956329,disc_loss 1.096015\n",
      "batch 48, gen_loss 0.999298,disc_loss 1.162531\n",
      "batch 49, gen_loss 1.027384,disc_loss 1.136203\n",
      "batch 50, gen_loss 0.978118,disc_loss 1.171759\n",
      "batch 51, gen_loss 0.953810,disc_loss 1.215751\n",
      "batch 52, gen_loss 0.899375,disc_loss 1.194816\n",
      "batch 53, gen_loss 0.810616,disc_loss 1.239936\n",
      "batch 54, gen_loss 0.814976,disc_loss 1.241696\n",
      "batch 55, gen_loss 0.873773,disc_loss 1.223161\n",
      "batch 56, gen_loss 0.935907,disc_loss 1.228693\n",
      "batch 57, gen_loss 0.939111,disc_loss 1.265572\n",
      "batch 58, gen_loss 0.894145,disc_loss 1.216808\n",
      "batch 59, gen_loss 0.845856,disc_loss 1.265492\n",
      "batch 60, gen_loss 0.827608,disc_loss 1.234350\n",
      "batch 61, gen_loss 0.850788,disc_loss 1.234235\n",
      "batch 62, gen_loss 0.834250,disc_loss 1.213509\n",
      "batch 63, gen_loss 0.879925,disc_loss 1.195802\n",
      "batch 64, gen_loss 0.922579,disc_loss 1.231942\n",
      "batch 65, gen_loss 0.914654,disc_loss 1.181986\n",
      "batch 66, gen_loss 0.893677,disc_loss 1.205671\n",
      "batch 67, gen_loss 0.873510,disc_loss 1.229664\n",
      "batch 68, gen_loss 0.863076,disc_loss 1.227351\n",
      "batch 69, gen_loss 0.841970,disc_loss 1.216324\n",
      "batch 70, gen_loss 0.855662,disc_loss 1.241628\n",
      "batch 71, gen_loss 0.844783,disc_loss 1.210716\n",
      "batch 72, gen_loss 0.895013,disc_loss 1.190567\n",
      "batch 73, gen_loss 0.872245,disc_loss 1.224169\n",
      "batch 74, gen_loss 0.870292,disc_loss 1.172874\n",
      "batch 75, gen_loss 0.898104,disc_loss 1.232212\n",
      "batch 76, gen_loss 0.849851,disc_loss 1.181982\n",
      "batch 77, gen_loss 0.843113,disc_loss 1.146101\n",
      "batch 78, gen_loss 0.885808,disc_loss 1.154179\n",
      "batch 79, gen_loss 0.938353,disc_loss 1.185421\n",
      "batch 80, gen_loss 0.926680,disc_loss 1.186481\n",
      "batch 81, gen_loss 0.881916,disc_loss 1.171851\n",
      "batch 82, gen_loss 0.857049,disc_loss 1.175457\n",
      "batch 83, gen_loss 0.860302,disc_loss 1.181159\n",
      "batch 84, gen_loss 0.905086,disc_loss 1.180237\n",
      "batch 85, gen_loss 0.894405,disc_loss 1.181398\n",
      "batch 86, gen_loss 0.914246,disc_loss 1.196426\n",
      "batch 87, gen_loss 0.901524,disc_loss 1.179358\n",
      "batch 88, gen_loss 0.886819,disc_loss 1.179866\n",
      "batch 89, gen_loss 0.882318,disc_loss 1.202115\n",
      "batch 90, gen_loss 0.881606,disc_loss 1.162267\n",
      "batch 91, gen_loss 0.871208,disc_loss 1.203634\n",
      "batch 92, gen_loss 0.890150,disc_loss 1.188997\n",
      "batch 93, gen_loss 0.902068,disc_loss 1.186029\n",
      "batch 94, gen_loss 0.887491,disc_loss 1.201798\n",
      "batch 95, gen_loss 0.854547,disc_loss 1.169009\n",
      "batch 96, gen_loss 0.879891,disc_loss 1.212809\n",
      "batch 97, gen_loss 0.873944,disc_loss 1.251347\n",
      "batch 98, gen_loss 0.896141,disc_loss 1.254602\n",
      "batch 99, gen_loss 0.859937,disc_loss 1.180661\n",
      "batch 100, gen_loss 0.886750,disc_loss 1.285830\n",
      "batch 101, gen_loss 0.851611,disc_loss 1.289555\n",
      "batch 102, gen_loss 0.829766,disc_loss 1.300817\n",
      "batch 103, gen_loss 0.795788,disc_loss 1.308222\n",
      "batch 104, gen_loss 0.781966,disc_loss 1.338029\n",
      "batch 105, gen_loss 0.779880,disc_loss 1.339043\n",
      "batch 106, gen_loss 0.816133,disc_loss 1.346180\n",
      "batch 107, gen_loss 0.913784,disc_loss 1.313794\n",
      "batch 108, gen_loss 0.853976,disc_loss 1.348856\n",
      "batch 109, gen_loss 0.837510,disc_loss 1.361304\n",
      "batch 110, gen_loss 0.743468,disc_loss 1.374068\n",
      "batch 111, gen_loss 0.747783,disc_loss 1.368044\n",
      "batch 112, gen_loss 0.754198,disc_loss 1.353907\n",
      "batch 113, gen_loss 0.801020,disc_loss 1.365556\n",
      "batch 114, gen_loss 0.864471,disc_loss 1.381767\n",
      "batch 115, gen_loss 0.851966,disc_loss 1.376568\n",
      "batch 116, gen_loss 0.825140,disc_loss 1.304191\n",
      "batch 117, gen_loss 0.770396,disc_loss 1.342249\n",
      "batch 118, gen_loss 0.758491,disc_loss 1.301537\n",
      "batch 119, gen_loss 0.826206,disc_loss 1.329290\n",
      "batch 120, gen_loss 0.855795,disc_loss 1.297196\n",
      "batch 121, gen_loss 0.868806,disc_loss 1.319644\n",
      "batch 122, gen_loss 0.877399,disc_loss 1.311510\n",
      "batch 123, gen_loss 0.826508,disc_loss 1.328379\n",
      "batch 124, gen_loss 0.824460,disc_loss 1.281965\n",
      "batch 125, gen_loss 0.806390,disc_loss 1.291595\n",
      "batch 126, gen_loss 0.796036,disc_loss 1.308030\n",
      "batch 127, gen_loss 0.864980,disc_loss 1.244196\n",
      "batch 128, gen_loss 0.957955,disc_loss 1.236487\n",
      "batch 129, gen_loss 0.975185,disc_loss 1.223068\n",
      "batch 130, gen_loss 0.911079,disc_loss 1.218432\n",
      "batch 131, gen_loss 0.882731,disc_loss 1.184624\n",
      "batch 132, gen_loss 0.850661,disc_loss 1.247423\n",
      "batch 133, gen_loss 0.854389,disc_loss 1.195607\n",
      "batch 134, gen_loss 0.946307,disc_loss 1.129741\n",
      "batch 135, gen_loss 0.967165,disc_loss 1.126629\n",
      "batch 136, gen_loss 0.951464,disc_loss 1.169073\n",
      "batch 137, gen_loss 0.987530,disc_loss 1.123419\n",
      "batch 138, gen_loss 0.982360,disc_loss 1.083971\n",
      "batch 139, gen_loss 0.960478,disc_loss 1.107955\n",
      "batch 140, gen_loss 0.944112,disc_loss 1.101519\n",
      "batch 141, gen_loss 0.997457,disc_loss 1.054868\n",
      "batch 142, gen_loss 1.027022,disc_loss 1.058536\n",
      "batch 143, gen_loss 1.047408,disc_loss 1.099633\n",
      "batch 144, gen_loss 1.025491,disc_loss 1.051476\n",
      "batch 145, gen_loss 1.037213,disc_loss 0.997243\n",
      "batch 146, gen_loss 0.982279,disc_loss 1.095624\n",
      "batch 147, gen_loss 1.011108,disc_loss 1.039838\n",
      "batch 148, gen_loss 0.995290,disc_loss 1.042732\n",
      "batch 149, gen_loss 1.001229,disc_loss 1.015314\n",
      "batch 150, gen_loss 1.015971,disc_loss 1.049234\n",
      "batch 151, gen_loss 1.058741,disc_loss 1.074209\n",
      "batch 152, gen_loss 1.053019,disc_loss 1.040772\n",
      "batch 153, gen_loss 1.070733,disc_loss 1.064681\n",
      "batch 154, gen_loss 0.975152,disc_loss 1.124094\n",
      "batch 155, gen_loss 0.952981,disc_loss 1.069228\n",
      "batch 156, gen_loss 0.954167,disc_loss 1.099252\n",
      "batch 157, gen_loss 0.974285,disc_loss 1.077692\n",
      "batch 158, gen_loss 1.045703,disc_loss 1.054946\n",
      "batch 159, gen_loss 1.046300,disc_loss 1.100973\n",
      "batch 160, gen_loss 1.035320,disc_loss 1.115509\n",
      "batch 161, gen_loss 0.970307,disc_loss 1.157443\n",
      "batch 162, gen_loss 0.894262,disc_loss 1.150148\n",
      "batch 163, gen_loss 0.877413,disc_loss 1.126786\n",
      "batch 164, gen_loss 0.914123,disc_loss 1.193422\n",
      "batch 165, gen_loss 0.955578,disc_loss 1.188518\n",
      "batch 166, gen_loss 0.983613,disc_loss 1.144478\n",
      "batch 167, gen_loss 0.982527,disc_loss 1.248502\n",
      "batch 168, gen_loss 0.893969,disc_loss 1.228922\n",
      "batch 169, gen_loss 0.831398,disc_loss 1.212108\n",
      "batch 170, gen_loss 0.826042,disc_loss 1.176767\n",
      "batch 171, gen_loss 0.858832,disc_loss 1.220771\n",
      "batch 172, gen_loss 0.906791,disc_loss 1.256843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 173, gen_loss 0.990289,disc_loss 1.169292\n",
      "batch 174, gen_loss 0.950982,disc_loss 1.175971\n",
      "batch 175, gen_loss 0.937080,disc_loss 1.220221\n",
      "batch 176, gen_loss 0.883481,disc_loss 1.195262\n",
      "batch 177, gen_loss 0.850060,disc_loss 1.177074\n",
      "batch 178, gen_loss 0.826223,disc_loss 1.278283\n",
      "batch 179, gen_loss 0.889309,disc_loss 1.275254\n",
      "batch 180, gen_loss 0.913712,disc_loss 1.251011\n",
      "batch 181, gen_loss 0.870262,disc_loss 1.223617\n",
      "batch 182, gen_loss 0.880946,disc_loss 1.306237\n",
      "batch 183, gen_loss 0.874752,disc_loss 1.222107\n",
      "batch 184, gen_loss 0.837633,disc_loss 1.287967\n",
      "batch 185, gen_loss 0.802721,disc_loss 1.253617\n",
      "batch 186, gen_loss 0.896647,disc_loss 1.235566\n",
      "batch 187, gen_loss 0.883229,disc_loss 1.293364\n",
      "batch 188, gen_loss 0.858424,disc_loss 1.252527\n",
      "batch 189, gen_loss 0.888885,disc_loss 1.203009\n",
      "batch 190, gen_loss 0.856396,disc_loss 1.202087\n",
      "batch 191, gen_loss 0.862180,disc_loss 1.285585\n",
      "batch 192, gen_loss 0.881782,disc_loss 1.231749\n",
      "batch 193, gen_loss 0.924560,disc_loss 1.221682\n",
      "batch 194, gen_loss 0.906208,disc_loss 1.202030\n",
      "batch 195, gen_loss 0.876665,disc_loss 1.268518\n",
      "batch 196, gen_loss 0.870525,disc_loss 1.238704\n",
      "batch 197, gen_loss 0.866566,disc_loss 1.209801\n",
      "batch 198, gen_loss 0.903782,disc_loss 1.219776\n",
      "batch 199, gen_loss 0.877879,disc_loss 1.216779\n",
      "batch 200, gen_loss 0.923398,disc_loss 1.210687\n",
      "batch 201, gen_loss 0.906981,disc_loss 1.211237\n",
      "batch 202, gen_loss 0.868145,disc_loss 1.195556\n",
      "batch 203, gen_loss 0.949342,disc_loss 1.177593\n",
      "batch 204, gen_loss 0.937247,disc_loss 1.160666\n",
      "batch 205, gen_loss 0.901447,disc_loss 1.230807\n",
      "batch 206, gen_loss 0.904302,disc_loss 1.170180\n",
      "batch 207, gen_loss 0.974658,disc_loss 1.148614\n",
      "batch 208, gen_loss 0.914290,disc_loss 1.189375\n",
      "batch 209, gen_loss 0.903635,disc_loss 1.192085\n",
      "batch 210, gen_loss 0.928064,disc_loss 1.162857\n",
      "batch 211, gen_loss 0.926519,disc_loss 1.177238\n",
      "batch 212, gen_loss 0.900856,disc_loss 1.199357\n",
      "batch 213, gen_loss 0.957963,disc_loss 1.135938\n",
      "batch 214, gen_loss 0.974892,disc_loss 1.150049\n",
      "batch 215, gen_loss 0.924741,disc_loss 1.152298\n",
      "batch 216, gen_loss 0.965238,disc_loss 1.199389\n",
      "batch 217, gen_loss 1.000742,disc_loss 1.142112\n",
      "batch 218, gen_loss 0.998245,disc_loss 1.110852\n",
      "batch 219, gen_loss 0.963139,disc_loss 1.135643\n",
      "batch 220, gen_loss 0.904973,disc_loss 1.152202\n",
      "batch 221, gen_loss 0.924843,disc_loss 1.125325\n",
      "batch 222, gen_loss 1.006096,disc_loss 1.158978\n",
      "batch 223, gen_loss 0.980236,disc_loss 1.159254\n",
      "batch 224, gen_loss 0.985975,disc_loss 1.151223\n",
      "batch 225, gen_loss 0.963675,disc_loss 1.119675\n",
      "batch 226, gen_loss 0.937255,disc_loss 1.167897\n",
      "batch 227, gen_loss 0.902930,disc_loss 1.178425\n",
      "batch 228, gen_loss 0.943819,disc_loss 1.128002\n",
      "batch 229, gen_loss 0.906599,disc_loss 1.181016\n",
      "batch 230, gen_loss 0.918607,disc_loss 1.184898\n",
      "batch 231, gen_loss 0.960282,disc_loss 1.171122\n",
      "batch 232, gen_loss 0.958378,disc_loss 1.153838\n",
      "batch 233, gen_loss 0.955712,disc_loss 1.147791\n",
      "batch 234, gen_loss 0.951119,disc_loss 1.171506\n",
      "batch 0, gen_loss 0.903038,disc_loss 1.164960\n",
      "batch 1, gen_loss 0.878066,disc_loss 1.184294\n",
      "batch 2, gen_loss 0.908422,disc_loss 1.183466\n",
      "batch 3, gen_loss 0.948883,disc_loss 1.171470\n",
      "batch 4, gen_loss 0.991162,disc_loss 1.195906\n",
      "batch 5, gen_loss 0.961213,disc_loss 1.159334\n",
      "batch 6, gen_loss 0.963992,disc_loss 1.159284\n",
      "batch 7, gen_loss 0.904329,disc_loss 1.181634\n",
      "batch 8, gen_loss 0.884343,disc_loss 1.188266\n",
      "batch 9, gen_loss 0.902023,disc_loss 1.237767\n",
      "batch 10, gen_loss 0.863912,disc_loss 1.214967\n",
      "batch 11, gen_loss 0.875423,disc_loss 1.200997\n",
      "batch 12, gen_loss 0.886740,disc_loss 1.238730\n",
      "batch 13, gen_loss 0.878770,disc_loss 1.230336\n",
      "batch 14, gen_loss 0.849573,disc_loss 1.318487\n",
      "batch 15, gen_loss 0.844725,disc_loss 1.296552\n",
      "batch 16, gen_loss 0.819953,disc_loss 1.347816\n",
      "batch 17, gen_loss 0.847534,disc_loss 1.297902\n",
      "batch 18, gen_loss 0.793898,disc_loss 1.348610\n",
      "batch 19, gen_loss 0.784133,disc_loss 1.383603\n",
      "batch 20, gen_loss 0.772978,disc_loss 1.412539\n",
      "batch 21, gen_loss 0.803937,disc_loss 1.342053\n",
      "batch 22, gen_loss 0.712453,disc_loss 1.491703\n",
      "batch 23, gen_loss 0.778345,disc_loss 1.400364\n",
      "batch 24, gen_loss 0.813154,disc_loss 1.387199\n",
      "batch 25, gen_loss 0.724600,disc_loss 1.461235\n",
      "batch 26, gen_loss 0.769843,disc_loss 1.399718\n",
      "batch 27, gen_loss 0.746607,disc_loss 1.405654\n",
      "batch 28, gen_loss 0.751574,disc_loss 1.429937\n",
      "batch 29, gen_loss 0.756804,disc_loss 1.436214\n",
      "batch 30, gen_loss 0.766546,disc_loss 1.402287\n",
      "batch 31, gen_loss 0.725572,disc_loss 1.423298\n",
      "batch 32, gen_loss 0.779426,disc_loss 1.342081\n",
      "batch 33, gen_loss 0.759618,disc_loss 1.359619\n",
      "batch 34, gen_loss 0.759585,disc_loss 1.399624\n",
      "batch 35, gen_loss 0.771393,disc_loss 1.358675\n",
      "batch 36, gen_loss 0.797132,disc_loss 1.379557\n",
      "batch 37, gen_loss 0.781969,disc_loss 1.361839\n",
      "batch 38, gen_loss 0.805777,disc_loss 1.328422\n",
      "batch 39, gen_loss 0.794738,disc_loss 1.318825\n",
      "batch 40, gen_loss 0.801358,disc_loss 1.288184\n",
      "batch 41, gen_loss 0.803377,disc_loss 1.228343\n",
      "batch 42, gen_loss 0.820249,disc_loss 1.212827\n",
      "batch 43, gen_loss 0.841147,disc_loss 1.248570\n",
      "batch 44, gen_loss 0.866061,disc_loss 1.215422\n",
      "batch 45, gen_loss 0.923503,disc_loss 1.195904\n",
      "batch 46, gen_loss 0.971813,disc_loss 1.182362\n",
      "batch 47, gen_loss 0.992333,disc_loss 1.089557\n",
      "batch 48, gen_loss 0.953066,disc_loss 1.164933\n",
      "batch 49, gen_loss 0.947727,disc_loss 1.085521\n",
      "batch 50, gen_loss 0.891280,disc_loss 1.136346\n",
      "batch 51, gen_loss 0.908938,disc_loss 1.126785\n",
      "batch 52, gen_loss 1.004655,disc_loss 1.033738\n",
      "batch 53, gen_loss 1.046910,disc_loss 1.098150\n",
      "batch 54, gen_loss 1.071853,disc_loss 1.104353\n",
      "batch 55, gen_loss 1.049361,disc_loss 1.067321\n",
      "batch 56, gen_loss 1.033311,disc_loss 1.117896\n",
      "batch 57, gen_loss 0.989163,disc_loss 1.038233\n",
      "batch 58, gen_loss 0.971517,disc_loss 1.079827\n",
      "batch 59, gen_loss 1.029067,disc_loss 1.083073\n",
      "batch 60, gen_loss 1.074187,disc_loss 1.042460\n",
      "batch 61, gen_loss 1.031630,disc_loss 1.154677\n",
      "batch 62, gen_loss 1.120512,disc_loss 1.077757\n",
      "batch 63, gen_loss 0.986652,disc_loss 1.172020\n",
      "batch 64, gen_loss 0.960453,disc_loss 1.191767\n",
      "batch 65, gen_loss 0.935011,disc_loss 1.122959\n",
      "batch 66, gen_loss 0.970373,disc_loss 1.203654\n",
      "batch 67, gen_loss 1.021341,disc_loss 1.172200\n",
      "batch 68, gen_loss 1.042511,disc_loss 1.135110\n",
      "batch 69, gen_loss 0.987175,disc_loss 1.172724\n",
      "batch 70, gen_loss 0.972828,disc_loss 1.159351\n",
      "batch 71, gen_loss 1.007149,disc_loss 1.230831\n",
      "batch 72, gen_loss 0.967049,disc_loss 1.248691\n",
      "batch 73, gen_loss 0.947946,disc_loss 1.207592\n",
      "batch 74, gen_loss 0.893998,disc_loss 1.248899\n",
      "batch 75, gen_loss 0.898734,disc_loss 1.278255\n",
      "batch 76, gen_loss 0.925022,disc_loss 1.382579\n",
      "batch 77, gen_loss 0.983147,disc_loss 1.351521\n",
      "batch 78, gen_loss 0.951854,disc_loss 1.304605\n",
      "batch 79, gen_loss 0.946374,disc_loss 1.314079\n",
      "batch 80, gen_loss 0.916921,disc_loss 1.313950\n",
      "batch 81, gen_loss 0.896775,disc_loss 1.291642\n",
      "batch 82, gen_loss 0.884010,disc_loss 1.365260\n",
      "batch 83, gen_loss 0.965525,disc_loss 1.315813\n",
      "batch 84, gen_loss 0.957482,disc_loss 1.237067\n",
      "batch 85, gen_loss 0.931551,disc_loss 1.361452\n",
      "batch 86, gen_loss 0.898398,disc_loss 1.238914\n",
      "batch 87, gen_loss 0.902210,disc_loss 1.264331\n",
      "batch 88, gen_loss 0.901798,disc_loss 1.301855\n",
      "batch 89, gen_loss 0.944800,disc_loss 1.242621\n",
      "batch 90, gen_loss 0.967641,disc_loss 1.190853\n",
      "batch 91, gen_loss 0.966393,disc_loss 1.280090\n",
      "batch 92, gen_loss 0.934403,disc_loss 1.231440\n",
      "batch 93, gen_loss 0.973790,disc_loss 1.212125\n",
      "batch 94, gen_loss 0.948550,disc_loss 1.143613\n",
      "batch 95, gen_loss 0.954621,disc_loss 1.181528\n",
      "batch 96, gen_loss 0.979258,disc_loss 1.174126\n",
      "batch 97, gen_loss 0.996766,disc_loss 1.171760\n",
      "batch 98, gen_loss 1.045330,disc_loss 1.168325\n",
      "batch 99, gen_loss 0.981807,disc_loss 1.179765\n",
      "batch 100, gen_loss 1.056516,disc_loss 1.132210\n",
      "batch 101, gen_loss 1.018302,disc_loss 1.058669\n",
      "batch 102, gen_loss 0.983629,disc_loss 1.092803\n",
      "batch 103, gen_loss 1.043848,disc_loss 1.056517\n",
      "batch 104, gen_loss 1.129719,disc_loss 1.035469\n",
      "batch 105, gen_loss 1.166050,disc_loss 1.099273\n",
      "batch 106, gen_loss 1.074718,disc_loss 1.108990\n",
      "batch 107, gen_loss 1.021115,disc_loss 1.083690\n",
      "batch 108, gen_loss 0.977934,disc_loss 1.089029\n",
      "batch 109, gen_loss 1.070084,disc_loss 1.058481\n",
      "batch 110, gen_loss 1.115980,disc_loss 1.071441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 111, gen_loss 1.138852,disc_loss 1.022417\n",
      "batch 112, gen_loss 1.130996,disc_loss 1.081030\n",
      "batch 113, gen_loss 1.075939,disc_loss 1.003162\n",
      "batch 114, gen_loss 1.126298,disc_loss 1.020494\n",
      "batch 115, gen_loss 1.160593,disc_loss 1.077261\n",
      "batch 116, gen_loss 1.180021,disc_loss 1.057745\n",
      "batch 117, gen_loss 1.112771,disc_loss 1.079287\n",
      "batch 118, gen_loss 1.095969,disc_loss 1.094552\n",
      "batch 119, gen_loss 1.087441,disc_loss 1.154312\n",
      "batch 120, gen_loss 1.067839,disc_loss 1.142258\n",
      "batch 121, gen_loss 1.025979,disc_loss 1.124278\n",
      "batch 122, gen_loss 1.002599,disc_loss 1.183768\n",
      "batch 123, gen_loss 1.080135,disc_loss 1.179554\n",
      "batch 124, gen_loss 1.064325,disc_loss 1.215682\n",
      "batch 125, gen_loss 1.057119,disc_loss 1.129614\n",
      "batch 126, gen_loss 1.011078,disc_loss 1.245931\n",
      "batch 127, gen_loss 0.969010,disc_loss 1.251679\n",
      "batch 128, gen_loss 0.982819,disc_loss 1.196506\n",
      "batch 129, gen_loss 1.021331,disc_loss 1.258177\n",
      "batch 130, gen_loss 1.007038,disc_loss 1.285619\n",
      "batch 131, gen_loss 0.938773,disc_loss 1.296852\n",
      "batch 132, gen_loss 0.907654,disc_loss 1.318454\n",
      "batch 133, gen_loss 0.838410,disc_loss 1.339894\n",
      "batch 134, gen_loss 0.887762,disc_loss 1.366016\n",
      "batch 135, gen_loss 0.951140,disc_loss 1.266690\n",
      "batch 136, gen_loss 0.915322,disc_loss 1.409832\n",
      "batch 137, gen_loss 0.912915,disc_loss 1.293909\n",
      "batch 138, gen_loss 0.831299,disc_loss 1.400855\n",
      "batch 139, gen_loss 0.824473,disc_loss 1.352858\n",
      "batch 140, gen_loss 0.790657,disc_loss 1.398943\n",
      "batch 141, gen_loss 0.839066,disc_loss 1.347895\n",
      "batch 142, gen_loss 0.891027,disc_loss 1.393472\n",
      "batch 143, gen_loss 0.846134,disc_loss 1.337935\n",
      "batch 144, gen_loss 0.855993,disc_loss 1.299885\n",
      "batch 145, gen_loss 0.837393,disc_loss 1.289638\n",
      "batch 146, gen_loss 0.829468,disc_loss 1.405243\n",
      "batch 147, gen_loss 0.856712,disc_loss 1.344464\n",
      "batch 148, gen_loss 0.879635,disc_loss 1.285802\n",
      "batch 149, gen_loss 0.821547,disc_loss 1.397328\n",
      "batch 150, gen_loss 0.809695,disc_loss 1.410140\n",
      "batch 151, gen_loss 0.828387,disc_loss 1.327431\n",
      "batch 152, gen_loss 0.797455,disc_loss 1.307352\n",
      "batch 153, gen_loss 0.841416,disc_loss 1.201927\n",
      "batch 154, gen_loss 0.887549,disc_loss 1.343041\n",
      "batch 155, gen_loss 0.878392,disc_loss 1.302710\n",
      "batch 156, gen_loss 0.908739,disc_loss 1.286124\n",
      "batch 157, gen_loss 0.874187,disc_loss 1.292253\n",
      "batch 158, gen_loss 0.861503,disc_loss 1.236543\n",
      "batch 159, gen_loss 0.881400,disc_loss 1.249014\n",
      "batch 160, gen_loss 0.873824,disc_loss 1.275033\n",
      "batch 161, gen_loss 0.948149,disc_loss 1.304530\n",
      "batch 162, gen_loss 0.932120,disc_loss 1.198528\n",
      "batch 163, gen_loss 0.944672,disc_loss 1.239885\n",
      "batch 164, gen_loss 0.881677,disc_loss 1.289917\n",
      "batch 165, gen_loss 0.932274,disc_loss 1.274728\n",
      "batch 166, gen_loss 0.960263,disc_loss 1.252638\n",
      "batch 167, gen_loss 0.920611,disc_loss 1.227617\n",
      "batch 168, gen_loss 0.879449,disc_loss 1.284583\n",
      "batch 169, gen_loss 0.943389,disc_loss 1.276613\n",
      "batch 170, gen_loss 0.970787,disc_loss 1.303125\n",
      "batch 171, gen_loss 0.938722,disc_loss 1.212437\n",
      "batch 172, gen_loss 0.914755,disc_loss 1.274509\n",
      "batch 173, gen_loss 0.925728,disc_loss 1.271817\n",
      "batch 174, gen_loss 0.932050,disc_loss 1.319129\n",
      "batch 175, gen_loss 0.961571,disc_loss 1.238888\n",
      "batch 176, gen_loss 0.975703,disc_loss 1.228538\n",
      "batch 177, gen_loss 0.944791,disc_loss 1.281932\n",
      "batch 178, gen_loss 0.946857,disc_loss 1.259898\n",
      "batch 179, gen_loss 0.950043,disc_loss 1.336482\n",
      "batch 180, gen_loss 0.942816,disc_loss 1.308537\n",
      "batch 181, gen_loss 0.904309,disc_loss 1.379372\n",
      "batch 182, gen_loss 0.877779,disc_loss 1.388924\n",
      "batch 183, gen_loss 0.883185,disc_loss 1.439676\n",
      "batch 184, gen_loss 0.920179,disc_loss 1.395549\n",
      "batch 185, gen_loss 0.883374,disc_loss 1.476553\n",
      "batch 186, gen_loss 0.904730,disc_loss 1.486358\n",
      "batch 187, gen_loss 0.810394,disc_loss 1.526553\n",
      "batch 188, gen_loss 0.827247,disc_loss 1.630271\n",
      "batch 189, gen_loss 0.820053,disc_loss 1.639345\n",
      "batch 190, gen_loss 0.830231,disc_loss 1.636616\n",
      "batch 191, gen_loss 0.722236,disc_loss 1.725467\n",
      "batch 192, gen_loss 0.805816,disc_loss 1.766837\n",
      "batch 193, gen_loss 0.742759,disc_loss 1.691233\n",
      "batch 194, gen_loss 0.733399,disc_loss 1.695098\n",
      "batch 195, gen_loss 0.732735,disc_loss 1.741037\n",
      "batch 196, gen_loss 0.727057,disc_loss 1.813220\n",
      "batch 197, gen_loss 0.732207,disc_loss 1.775900\n",
      "batch 198, gen_loss 0.652078,disc_loss 1.866307\n",
      "batch 199, gen_loss 0.701144,disc_loss 1.922776\n",
      "batch 200, gen_loss 0.676985,disc_loss 1.840533\n",
      "batch 201, gen_loss 0.686854,disc_loss 1.876719\n",
      "batch 202, gen_loss 0.659094,disc_loss 1.940636\n",
      "batch 203, gen_loss 0.653902,disc_loss 1.871716\n",
      "batch 204, gen_loss 0.640851,disc_loss 1.954791\n",
      "batch 205, gen_loss 0.624904,disc_loss 1.899060\n",
      "batch 206, gen_loss 0.601323,disc_loss 1.985944\n",
      "batch 207, gen_loss 0.571820,disc_loss 2.003541\n",
      "batch 208, gen_loss 0.648680,disc_loss 2.006286\n",
      "batch 209, gen_loss 0.622113,disc_loss 1.902284\n",
      "batch 210, gen_loss 0.613153,disc_loss 1.924492\n",
      "batch 211, gen_loss 0.638610,disc_loss 1.847624\n",
      "batch 212, gen_loss 0.588668,disc_loss 1.929107\n",
      "batch 213, gen_loss 0.643036,disc_loss 1.911272\n",
      "batch 214, gen_loss 0.639995,disc_loss 1.889106\n",
      "batch 215, gen_loss 0.616212,disc_loss 1.830585\n",
      "batch 216, gen_loss 0.594692,disc_loss 1.827923\n",
      "batch 217, gen_loss 0.605100,disc_loss 1.845404\n",
      "batch 218, gen_loss 0.620679,disc_loss 1.838027\n",
      "batch 219, gen_loss 0.670423,disc_loss 1.770757\n",
      "batch 220, gen_loss 0.695483,disc_loss 1.829325\n",
      "batch 221, gen_loss 0.661356,disc_loss 1.802259\n",
      "batch 222, gen_loss 0.614376,disc_loss 1.799991\n",
      "batch 223, gen_loss 0.564477,disc_loss 1.796423\n",
      "batch 224, gen_loss 0.591578,disc_loss 1.706182\n",
      "batch 225, gen_loss 0.613129,disc_loss 1.703576\n",
      "batch 226, gen_loss 0.671494,disc_loss 1.718295\n",
      "batch 227, gen_loss 0.692619,disc_loss 1.718074\n",
      "batch 228, gen_loss 0.712507,disc_loss 1.719880\n",
      "batch 229, gen_loss 0.661518,disc_loss 1.660623\n",
      "batch 230, gen_loss 0.640330,disc_loss 1.650899\n",
      "batch 231, gen_loss 0.633802,disc_loss 1.607914\n",
      "batch 232, gen_loss 0.631450,disc_loss 1.648783\n",
      "batch 233, gen_loss 0.658520,disc_loss 1.656279\n",
      "batch 234, gen_loss 0.714708,disc_loss 1.578546\n",
      "batch 0, gen_loss 0.693748,disc_loss 1.560126\n",
      "batch 1, gen_loss 0.716840,disc_loss 1.592577\n",
      "batch 2, gen_loss 0.716446,disc_loss 1.566067\n",
      "batch 3, gen_loss 0.700313,disc_loss 1.517872\n",
      "batch 4, gen_loss 0.682808,disc_loss 1.547813\n",
      "batch 5, gen_loss 0.701520,disc_loss 1.458004\n",
      "batch 6, gen_loss 0.708329,disc_loss 1.449711\n",
      "batch 7, gen_loss 0.730945,disc_loss 1.480303\n",
      "batch 8, gen_loss 0.726576,disc_loss 1.489472\n",
      "batch 9, gen_loss 0.751934,disc_loss 1.472231\n",
      "batch 10, gen_loss 0.754958,disc_loss 1.415764\n",
      "batch 11, gen_loss 0.770472,disc_loss 1.358440\n",
      "batch 12, gen_loss 0.781719,disc_loss 1.344357\n",
      "batch 13, gen_loss 0.754472,disc_loss 1.370411\n",
      "batch 14, gen_loss 0.781656,disc_loss 1.372649\n",
      "batch 15, gen_loss 0.771914,disc_loss 1.366136\n",
      "batch 16, gen_loss 0.791156,disc_loss 1.313815\n",
      "batch 17, gen_loss 0.748538,disc_loss 1.367389\n",
      "batch 18, gen_loss 0.785730,disc_loss 1.309308\n",
      "batch 19, gen_loss 0.838155,disc_loss 1.269218\n",
      "batch 20, gen_loss 0.823022,disc_loss 1.320908\n",
      "batch 21, gen_loss 0.829226,disc_loss 1.284735\n",
      "batch 22, gen_loss 0.829803,disc_loss 1.286631\n",
      "batch 23, gen_loss 0.816867,disc_loss 1.248497\n",
      "batch 24, gen_loss 0.780397,disc_loss 1.287372\n",
      "batch 25, gen_loss 0.804825,disc_loss 1.262656\n",
      "batch 26, gen_loss 0.836056,disc_loss 1.269349\n",
      "batch 27, gen_loss 0.851113,disc_loss 1.244059\n",
      "batch 28, gen_loss 0.837670,disc_loss 1.236315\n",
      "batch 29, gen_loss 0.841527,disc_loss 1.226245\n",
      "batch 30, gen_loss 0.870842,disc_loss 1.218932\n",
      "batch 31, gen_loss 0.850929,disc_loss 1.237261\n",
      "batch 32, gen_loss 0.883876,disc_loss 1.169207\n",
      "batch 33, gen_loss 0.840099,disc_loss 1.220889\n",
      "batch 34, gen_loss 0.848280,disc_loss 1.245845\n",
      "batch 35, gen_loss 0.833613,disc_loss 1.213779\n",
      "batch 36, gen_loss 0.858788,disc_loss 1.193245\n",
      "batch 37, gen_loss 0.858433,disc_loss 1.181932\n",
      "batch 38, gen_loss 0.864496,disc_loss 1.224888\n",
      "batch 39, gen_loss 0.858711,disc_loss 1.185827\n",
      "batch 40, gen_loss 0.895639,disc_loss 1.186603\n",
      "batch 41, gen_loss 0.865813,disc_loss 1.201092\n",
      "batch 42, gen_loss 0.870506,disc_loss 1.181092\n",
      "batch 43, gen_loss 0.864838,disc_loss 1.197125\n",
      "batch 44, gen_loss 0.861942,disc_loss 1.206813\n",
      "batch 45, gen_loss 0.899874,disc_loss 1.158362\n",
      "batch 46, gen_loss 0.905747,disc_loss 1.160191\n",
      "batch 47, gen_loss 0.891496,disc_loss 1.197076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 48, gen_loss 0.860003,disc_loss 1.183185\n",
      "batch 49, gen_loss 0.874634,disc_loss 1.181753\n",
      "batch 50, gen_loss 0.867800,disc_loss 1.161881\n",
      "batch 51, gen_loss 0.896784,disc_loss 1.140034\n",
      "batch 52, gen_loss 0.887451,disc_loss 1.214212\n",
      "batch 53, gen_loss 0.880542,disc_loss 1.210796\n",
      "batch 54, gen_loss 0.889363,disc_loss 1.206561\n",
      "batch 55, gen_loss 0.859282,disc_loss 1.224716\n",
      "batch 56, gen_loss 0.823953,disc_loss 1.172330\n",
      "batch 57, gen_loss 0.823742,disc_loss 1.228231\n",
      "batch 58, gen_loss 0.831765,disc_loss 1.229645\n",
      "batch 59, gen_loss 0.865192,disc_loss 1.226700\n",
      "batch 60, gen_loss 0.891472,disc_loss 1.202539\n",
      "batch 61, gen_loss 0.881751,disc_loss 1.238068\n",
      "batch 62, gen_loss 0.875392,disc_loss 1.282140\n",
      "batch 63, gen_loss 0.831387,disc_loss 1.229341\n",
      "batch 64, gen_loss 0.815523,disc_loss 1.268093\n",
      "batch 65, gen_loss 0.804122,disc_loss 1.234461\n",
      "batch 66, gen_loss 0.809946,disc_loss 1.275426\n",
      "batch 67, gen_loss 0.846358,disc_loss 1.237062\n",
      "batch 68, gen_loss 0.832396,disc_loss 1.285389\n",
      "batch 69, gen_loss 0.832619,disc_loss 1.269976\n",
      "batch 70, gen_loss 0.815396,disc_loss 1.289151\n",
      "batch 71, gen_loss 0.849275,disc_loss 1.257745\n",
      "batch 72, gen_loss 0.826749,disc_loss 1.299263\n",
      "batch 73, gen_loss 0.775421,disc_loss 1.290498\n",
      "batch 74, gen_loss 0.815199,disc_loss 1.284639\n",
      "batch 75, gen_loss 0.810902,disc_loss 1.278215\n",
      "batch 76, gen_loss 0.807097,disc_loss 1.309573\n",
      "batch 77, gen_loss 0.805579,disc_loss 1.324079\n",
      "batch 78, gen_loss 0.787167,disc_loss 1.294906\n",
      "batch 79, gen_loss 0.777488,disc_loss 1.333295\n",
      "batch 80, gen_loss 0.797564,disc_loss 1.311840\n",
      "batch 81, gen_loss 0.757307,disc_loss 1.311410\n",
      "batch 82, gen_loss 0.811629,disc_loss 1.329509\n",
      "batch 83, gen_loss 0.811585,disc_loss 1.330536\n",
      "batch 84, gen_loss 0.779057,disc_loss 1.352048\n",
      "batch 85, gen_loss 0.789091,disc_loss 1.330475\n",
      "batch 86, gen_loss 0.768353,disc_loss 1.292774\n",
      "batch 87, gen_loss 0.762567,disc_loss 1.386305\n",
      "batch 88, gen_loss 0.742311,disc_loss 1.355030\n",
      "batch 89, gen_loss 0.742775,disc_loss 1.359985\n",
      "batch 90, gen_loss 0.759087,disc_loss 1.305094\n",
      "batch 91, gen_loss 0.759415,disc_loss 1.344588\n",
      "batch 92, gen_loss 0.780818,disc_loss 1.350214\n",
      "batch 93, gen_loss 0.757155,disc_loss 1.327380\n",
      "batch 94, gen_loss 0.778268,disc_loss 1.304291\n",
      "batch 95, gen_loss 0.774321,disc_loss 1.300603\n",
      "batch 96, gen_loss 0.762202,disc_loss 1.308077\n",
      "batch 97, gen_loss 0.766159,disc_loss 1.311379\n",
      "batch 98, gen_loss 0.783310,disc_loss 1.291438\n",
      "batch 99, gen_loss 0.788128,disc_loss 1.262054\n",
      "batch 100, gen_loss 0.798115,disc_loss 1.271734\n",
      "batch 101, gen_loss 0.807155,disc_loss 1.263212\n",
      "batch 102, gen_loss 0.810276,disc_loss 1.243646\n",
      "batch 103, gen_loss 0.810930,disc_loss 1.230643\n",
      "batch 104, gen_loss 0.768572,disc_loss 1.282972\n",
      "batch 105, gen_loss 0.823336,disc_loss 1.251466\n",
      "batch 106, gen_loss 0.814941,disc_loss 1.228987\n",
      "batch 107, gen_loss 0.825396,disc_loss 1.198087\n",
      "batch 108, gen_loss 0.840935,disc_loss 1.165226\n",
      "batch 109, gen_loss 0.806681,disc_loss 1.209990\n",
      "batch 110, gen_loss 0.825889,disc_loss 1.181537\n",
      "batch 111, gen_loss 0.859812,disc_loss 1.151157\n",
      "batch 112, gen_loss 0.851926,disc_loss 1.151106\n",
      "batch 113, gen_loss 0.866817,disc_loss 1.161394\n",
      "batch 114, gen_loss 0.875916,disc_loss 1.132150\n",
      "batch 115, gen_loss 0.869781,disc_loss 1.118630\n",
      "batch 116, gen_loss 0.886346,disc_loss 1.166663\n",
      "batch 117, gen_loss 0.858269,disc_loss 1.149434\n",
      "batch 118, gen_loss 0.875633,disc_loss 1.085265\n",
      "batch 119, gen_loss 0.883787,disc_loss 1.111882\n",
      "batch 120, gen_loss 0.913507,disc_loss 1.079766\n",
      "batch 121, gen_loss 0.889803,disc_loss 1.104117\n",
      "batch 122, gen_loss 0.946323,disc_loss 1.074604\n",
      "batch 123, gen_loss 0.977420,disc_loss 1.077291\n",
      "batch 124, gen_loss 0.955802,disc_loss 1.061751\n",
      "batch 125, gen_loss 0.934484,disc_loss 1.078645\n",
      "batch 126, gen_loss 0.947192,disc_loss 1.055779\n",
      "batch 127, gen_loss 0.915721,disc_loss 1.075891\n",
      "batch 128, gen_loss 0.905810,disc_loss 1.045780\n",
      "batch 129, gen_loss 0.909512,disc_loss 1.068710\n",
      "batch 130, gen_loss 0.937417,disc_loss 1.089452\n",
      "batch 131, gen_loss 0.955933,disc_loss 1.093719\n",
      "batch 132, gen_loss 0.977041,disc_loss 1.063063\n",
      "batch 133, gen_loss 0.963082,disc_loss 1.121699\n",
      "batch 134, gen_loss 0.949250,disc_loss 1.087469\n",
      "batch 135, gen_loss 0.923257,disc_loss 1.126155\n",
      "batch 136, gen_loss 0.900506,disc_loss 1.147699\n",
      "batch 137, gen_loss 0.867085,disc_loss 1.161266\n",
      "batch 138, gen_loss 0.866589,disc_loss 1.157869\n",
      "batch 139, gen_loss 0.896633,disc_loss 1.156614\n",
      "batch 140, gen_loss 0.899673,disc_loss 1.179229\n",
      "batch 141, gen_loss 0.914271,disc_loss 1.217908\n",
      "batch 142, gen_loss 0.878583,disc_loss 1.222948\n",
      "batch 143, gen_loss 0.832672,disc_loss 1.254333\n",
      "batch 144, gen_loss 0.874346,disc_loss 1.243190\n",
      "batch 145, gen_loss 0.823289,disc_loss 1.294253\n",
      "batch 146, gen_loss 0.850546,disc_loss 1.255601\n",
      "batch 147, gen_loss 0.777354,disc_loss 1.362755\n",
      "batch 148, gen_loss 0.848981,disc_loss 1.284928\n",
      "batch 149, gen_loss 0.838787,disc_loss 1.290604\n",
      "batch 150, gen_loss 0.836847,disc_loss 1.330952\n",
      "batch 151, gen_loss 0.823814,disc_loss 1.343026\n",
      "batch 152, gen_loss 0.787645,disc_loss 1.385533\n",
      "batch 153, gen_loss 0.810418,disc_loss 1.379878\n",
      "batch 154, gen_loss 0.776019,disc_loss 1.414321\n",
      "batch 155, gen_loss 0.775730,disc_loss 1.404312\n",
      "batch 156, gen_loss 0.769974,disc_loss 1.472284\n",
      "batch 157, gen_loss 0.757078,disc_loss 1.465243\n",
      "batch 158, gen_loss 0.778907,disc_loss 1.438509\n",
      "batch 159, gen_loss 0.758112,disc_loss 1.436890\n",
      "batch 160, gen_loss 0.793941,disc_loss 1.515906\n",
      "batch 161, gen_loss 0.750494,disc_loss 1.509733\n",
      "batch 162, gen_loss 0.744752,disc_loss 1.467235\n",
      "batch 163, gen_loss 0.723100,disc_loss 1.515869\n",
      "batch 164, gen_loss 0.728073,disc_loss 1.513407\n",
      "batch 165, gen_loss 0.754916,disc_loss 1.489564\n",
      "batch 166, gen_loss 0.782898,disc_loss 1.497014\n",
      "batch 167, gen_loss 0.771913,disc_loss 1.507656\n",
      "batch 168, gen_loss 0.768522,disc_loss 1.478040\n",
      "batch 169, gen_loss 0.767916,disc_loss 1.517215\n",
      "batch 170, gen_loss 0.751035,disc_loss 1.476648\n",
      "batch 171, gen_loss 0.749148,disc_loss 1.449177\n",
      "batch 172, gen_loss 0.725530,disc_loss 1.440862\n",
      "batch 173, gen_loss 0.767349,disc_loss 1.446749\n",
      "batch 174, gen_loss 0.778750,disc_loss 1.441429\n",
      "batch 175, gen_loss 0.836890,disc_loss 1.435584\n",
      "batch 176, gen_loss 0.803202,disc_loss 1.391642\n",
      "batch 177, gen_loss 0.789681,disc_loss 1.413955\n",
      "batch 178, gen_loss 0.794711,disc_loss 1.365874\n",
      "batch 179, gen_loss 0.814949,disc_loss 1.338137\n",
      "batch 180, gen_loss 0.809488,disc_loss 1.337311\n",
      "batch 181, gen_loss 0.836725,disc_loss 1.327874\n",
      "batch 182, gen_loss 0.850318,disc_loss 1.309787\n",
      "batch 183, gen_loss 0.853799,disc_loss 1.312073\n",
      "batch 184, gen_loss 0.873353,disc_loss 1.289849\n",
      "batch 185, gen_loss 0.851180,disc_loss 1.299993\n",
      "batch 186, gen_loss 0.876146,disc_loss 1.259080\n",
      "batch 187, gen_loss 0.856075,disc_loss 1.279667\n",
      "batch 188, gen_loss 0.874672,disc_loss 1.255842\n",
      "batch 189, gen_loss 0.900160,disc_loss 1.238290\n",
      "batch 190, gen_loss 0.896416,disc_loss 1.259654\n",
      "batch 191, gen_loss 0.931520,disc_loss 1.202971\n",
      "batch 192, gen_loss 0.947110,disc_loss 1.158218\n",
      "batch 193, gen_loss 0.908621,disc_loss 1.158920\n",
      "batch 194, gen_loss 0.938169,disc_loss 1.193505\n",
      "batch 195, gen_loss 0.932714,disc_loss 1.187746\n",
      "batch 196, gen_loss 0.940836,disc_loss 1.122339\n",
      "batch 197, gen_loss 0.981234,disc_loss 1.192478\n",
      "batch 198, gen_loss 0.990992,disc_loss 1.165483\n",
      "batch 199, gen_loss 0.984291,disc_loss 1.162326\n",
      "batch 200, gen_loss 0.960344,disc_loss 1.139132\n",
      "batch 201, gen_loss 0.958966,disc_loss 1.157934\n",
      "batch 202, gen_loss 0.947598,disc_loss 1.153207\n",
      "batch 203, gen_loss 0.930449,disc_loss 1.127946\n",
      "batch 204, gen_loss 0.961011,disc_loss 1.174493\n",
      "batch 205, gen_loss 1.015683,disc_loss 1.172361\n",
      "batch 206, gen_loss 1.006832,disc_loss 1.154788\n",
      "batch 207, gen_loss 0.988578,disc_loss 1.157795\n",
      "batch 208, gen_loss 0.973456,disc_loss 1.182544\n",
      "batch 209, gen_loss 0.944498,disc_loss 1.171521\n",
      "batch 210, gen_loss 0.968512,disc_loss 1.163833\n",
      "batch 211, gen_loss 0.953511,disc_loss 1.236927\n",
      "batch 212, gen_loss 0.948367,disc_loss 1.124452\n",
      "batch 213, gen_loss 0.953987,disc_loss 1.149366\n",
      "batch 214, gen_loss 0.943561,disc_loss 1.197865\n",
      "batch 215, gen_loss 0.957373,disc_loss 1.249775\n",
      "batch 216, gen_loss 1.020685,disc_loss 1.223618\n",
      "batch 217, gen_loss 0.932999,disc_loss 1.218011\n",
      "batch 218, gen_loss 0.923714,disc_loss 1.161094\n",
      "batch 219, gen_loss 0.864676,disc_loss 1.235395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 220, gen_loss 0.877960,disc_loss 1.273269\n",
      "batch 221, gen_loss 0.873683,disc_loss 1.262623\n",
      "batch 222, gen_loss 0.886307,disc_loss 1.267099\n",
      "batch 223, gen_loss 0.886914,disc_loss 1.265039\n",
      "batch 224, gen_loss 0.888973,disc_loss 1.263961\n",
      "batch 225, gen_loss 0.854084,disc_loss 1.284708\n",
      "batch 226, gen_loss 0.841086,disc_loss 1.281223\n",
      "batch 227, gen_loss 0.821679,disc_loss 1.256835\n",
      "batch 228, gen_loss 0.848627,disc_loss 1.284970\n",
      "batch 229, gen_loss 0.815260,disc_loss 1.335358\n",
      "batch 230, gen_loss 0.833310,disc_loss 1.299550\n",
      "batch 231, gen_loss 0.830916,disc_loss 1.289692\n",
      "batch 232, gen_loss 0.800998,disc_loss 1.314103\n",
      "batch 233, gen_loss 0.800518,disc_loss 1.263860\n",
      "batch 234, gen_loss 0.796926,disc_loss 1.270785\n",
      "batch 0, gen_loss 0.842758,disc_loss 1.287923\n",
      "batch 1, gen_loss 0.814099,disc_loss 1.301116\n",
      "batch 2, gen_loss 0.789065,disc_loss 1.298562\n",
      "batch 3, gen_loss 0.771508,disc_loss 1.277773\n",
      "batch 4, gen_loss 0.780155,disc_loss 1.257676\n",
      "batch 5, gen_loss 0.804972,disc_loss 1.236809\n",
      "batch 6, gen_loss 0.829495,disc_loss 1.274142\n",
      "batch 7, gen_loss 0.841479,disc_loss 1.246458\n",
      "batch 8, gen_loss 0.829873,disc_loss 1.240119\n",
      "batch 9, gen_loss 0.856751,disc_loss 1.260862\n",
      "batch 10, gen_loss 0.860498,disc_loss 1.211212\n",
      "batch 11, gen_loss 0.838153,disc_loss 1.198073\n",
      "batch 12, gen_loss 0.844036,disc_loss 1.215237\n",
      "batch 13, gen_loss 0.876049,disc_loss 1.172107\n",
      "batch 14, gen_loss 0.862322,disc_loss 1.181593\n",
      "batch 15, gen_loss 0.898245,disc_loss 1.171701\n",
      "batch 16, gen_loss 0.942200,disc_loss 1.113137\n",
      "batch 17, gen_loss 0.963338,disc_loss 1.145516\n",
      "batch 18, gen_loss 0.976200,disc_loss 1.137422\n",
      "batch 19, gen_loss 0.938472,disc_loss 1.122268\n",
      "batch 20, gen_loss 0.966330,disc_loss 1.139386\n",
      "batch 21, gen_loss 0.997750,disc_loss 1.123299\n",
      "batch 22, gen_loss 0.963949,disc_loss 1.118707\n",
      "batch 23, gen_loss 0.973647,disc_loss 1.097289\n",
      "batch 24, gen_loss 0.992340,disc_loss 1.111203\n",
      "batch 25, gen_loss 1.033727,disc_loss 1.081894\n",
      "batch 26, gen_loss 1.036793,disc_loss 1.095910\n",
      "batch 27, gen_loss 1.038150,disc_loss 1.093134\n",
      "batch 28, gen_loss 1.033930,disc_loss 1.079528\n",
      "batch 29, gen_loss 1.098324,disc_loss 1.064898\n",
      "batch 30, gen_loss 1.041935,disc_loss 1.105847\n",
      "batch 31, gen_loss 1.063437,disc_loss 1.057011\n",
      "batch 32, gen_loss 1.051022,disc_loss 1.069993\n",
      "batch 33, gen_loss 1.070114,disc_loss 1.120176\n",
      "batch 34, gen_loss 0.986983,disc_loss 1.118383\n",
      "batch 35, gen_loss 1.017522,disc_loss 1.085161\n",
      "batch 36, gen_loss 1.058321,disc_loss 1.076418\n",
      "batch 37, gen_loss 1.022820,disc_loss 1.094764\n",
      "batch 38, gen_loss 1.006873,disc_loss 1.130616\n",
      "batch 39, gen_loss 0.998446,disc_loss 1.139333\n",
      "batch 40, gen_loss 0.945891,disc_loss 1.197695\n",
      "batch 41, gen_loss 1.011751,disc_loss 1.163005\n",
      "batch 42, gen_loss 0.953702,disc_loss 1.201119\n",
      "batch 43, gen_loss 0.946670,disc_loss 1.178548\n",
      "batch 44, gen_loss 0.883356,disc_loss 1.194199\n",
      "batch 45, gen_loss 0.881544,disc_loss 1.259558\n",
      "batch 46, gen_loss 0.916126,disc_loss 1.263412\n",
      "batch 47, gen_loss 0.840913,disc_loss 1.281543\n",
      "batch 48, gen_loss 0.907763,disc_loss 1.238582\n",
      "batch 49, gen_loss 0.821630,disc_loss 1.306735\n",
      "batch 50, gen_loss 0.857534,disc_loss 1.266868\n",
      "batch 51, gen_loss 0.855060,disc_loss 1.315043\n",
      "batch 52, gen_loss 0.828004,disc_loss 1.406818\n",
      "batch 53, gen_loss 0.774684,disc_loss 1.372733\n",
      "batch 54, gen_loss 0.774916,disc_loss 1.407661\n",
      "batch 55, gen_loss 0.759659,disc_loss 1.389206\n",
      "batch 56, gen_loss 0.792413,disc_loss 1.384029\n",
      "batch 57, gen_loss 0.776731,disc_loss 1.409255\n",
      "batch 58, gen_loss 0.768049,disc_loss 1.419229\n",
      "batch 59, gen_loss 0.769502,disc_loss 1.357088\n",
      "batch 60, gen_loss 0.758623,disc_loss 1.450600\n",
      "batch 61, gen_loss 0.765502,disc_loss 1.441531\n",
      "batch 62, gen_loss 0.769350,disc_loss 1.456841\n",
      "batch 63, gen_loss 0.767003,disc_loss 1.409192\n",
      "batch 64, gen_loss 0.759401,disc_loss 1.453360\n",
      "batch 65, gen_loss 0.738533,disc_loss 1.453850\n",
      "batch 66, gen_loss 0.779062,disc_loss 1.381691\n",
      "batch 67, gen_loss 0.744007,disc_loss 1.428482\n",
      "batch 68, gen_loss 0.753829,disc_loss 1.393327\n",
      "batch 69, gen_loss 0.772503,disc_loss 1.436910\n",
      "batch 70, gen_loss 0.795209,disc_loss 1.375126\n",
      "batch 71, gen_loss 0.802212,disc_loss 1.350810\n",
      "batch 72, gen_loss 0.806921,disc_loss 1.422424\n",
      "batch 73, gen_loss 0.807050,disc_loss 1.389520\n",
      "batch 74, gen_loss 0.779330,disc_loss 1.393060\n",
      "batch 75, gen_loss 0.772466,disc_loss 1.335103\n",
      "batch 76, gen_loss 0.776196,disc_loss 1.326035\n",
      "batch 77, gen_loss 0.781899,disc_loss 1.402839\n",
      "batch 78, gen_loss 0.800938,disc_loss 1.332285\n",
      "batch 79, gen_loss 0.822927,disc_loss 1.319006\n",
      "batch 80, gen_loss 0.831703,disc_loss 1.327456\n",
      "batch 81, gen_loss 0.837099,disc_loss 1.306906\n",
      "batch 82, gen_loss 0.858000,disc_loss 1.373109\n",
      "batch 83, gen_loss 0.856140,disc_loss 1.289883\n",
      "batch 84, gen_loss 0.855607,disc_loss 1.281901\n",
      "batch 85, gen_loss 0.836030,disc_loss 1.297429\n",
      "batch 86, gen_loss 0.803653,disc_loss 1.359655\n",
      "batch 87, gen_loss 0.831054,disc_loss 1.292846\n",
      "batch 88, gen_loss 0.818825,disc_loss 1.303735\n",
      "batch 89, gen_loss 0.831048,disc_loss 1.270226\n",
      "batch 90, gen_loss 0.832788,disc_loss 1.224515\n",
      "batch 91, gen_loss 0.846540,disc_loss 1.292841\n",
      "batch 92, gen_loss 0.867261,disc_loss 1.254133\n",
      "batch 93, gen_loss 0.848784,disc_loss 1.293029\n",
      "batch 94, gen_loss 0.865639,disc_loss 1.271031\n",
      "batch 95, gen_loss 0.855642,disc_loss 1.295162\n",
      "batch 96, gen_loss 0.828364,disc_loss 1.273783\n",
      "batch 97, gen_loss 0.813298,disc_loss 1.275716\n",
      "batch 98, gen_loss 0.843162,disc_loss 1.215532\n",
      "batch 99, gen_loss 0.837153,disc_loss 1.293154\n",
      "batch 100, gen_loss 0.838091,disc_loss 1.262829\n",
      "batch 101, gen_loss 0.881597,disc_loss 1.242824\n",
      "batch 102, gen_loss 0.872931,disc_loss 1.263582\n",
      "batch 103, gen_loss 0.855274,disc_loss 1.251281\n",
      "batch 104, gen_loss 0.877389,disc_loss 1.234886\n",
      "batch 105, gen_loss 0.856674,disc_loss 1.261482\n",
      "batch 106, gen_loss 0.833974,disc_loss 1.250201\n",
      "batch 107, gen_loss 0.826906,disc_loss 1.245087\n",
      "batch 108, gen_loss 0.825178,disc_loss 1.256662\n",
      "batch 109, gen_loss 0.841430,disc_loss 1.269576\n",
      "batch 110, gen_loss 0.861235,disc_loss 1.277328\n",
      "batch 111, gen_loss 0.853623,disc_loss 1.269469\n",
      "batch 112, gen_loss 0.853097,disc_loss 1.257133\n",
      "batch 113, gen_loss 0.843351,disc_loss 1.259436\n",
      "batch 114, gen_loss 0.850086,disc_loss 1.235674\n",
      "batch 115, gen_loss 0.821444,disc_loss 1.296589\n",
      "batch 116, gen_loss 0.822155,disc_loss 1.253797\n",
      "batch 117, gen_loss 0.832020,disc_loss 1.284801\n",
      "batch 118, gen_loss 0.837696,disc_loss 1.272838\n",
      "batch 119, gen_loss 0.861053,disc_loss 1.270055\n",
      "batch 120, gen_loss 0.872265,disc_loss 1.240503\n",
      "batch 121, gen_loss 0.859567,disc_loss 1.263461\n",
      "batch 122, gen_loss 0.873838,disc_loss 1.226369\n",
      "batch 123, gen_loss 0.849723,disc_loss 1.240153\n",
      "batch 124, gen_loss 0.839536,disc_loss 1.210267\n",
      "batch 125, gen_loss 0.867959,disc_loss 1.222174\n",
      "batch 126, gen_loss 0.862379,disc_loss 1.237303\n",
      "batch 127, gen_loss 0.874793,disc_loss 1.257370\n",
      "batch 128, gen_loss 0.881212,disc_loss 1.221386\n",
      "batch 129, gen_loss 0.879505,disc_loss 1.202335\n",
      "batch 130, gen_loss 0.860371,disc_loss 1.228344\n",
      "batch 131, gen_loss 0.878369,disc_loss 1.160772\n",
      "batch 132, gen_loss 0.856126,disc_loss 1.220987\n",
      "batch 133, gen_loss 0.899079,disc_loss 1.203515\n",
      "batch 134, gen_loss 0.909454,disc_loss 1.168162\n",
      "batch 135, gen_loss 0.889251,disc_loss 1.197449\n",
      "batch 136, gen_loss 0.919248,disc_loss 1.162374\n",
      "batch 137, gen_loss 0.911147,disc_loss 1.179534\n",
      "batch 138, gen_loss 0.901536,disc_loss 1.222025\n",
      "batch 139, gen_loss 0.873396,disc_loss 1.215571\n",
      "batch 140, gen_loss 0.896081,disc_loss 1.191596\n",
      "batch 141, gen_loss 0.892412,disc_loss 1.169309\n",
      "batch 142, gen_loss 0.879139,disc_loss 1.142734\n",
      "batch 143, gen_loss 0.909287,disc_loss 1.176878\n",
      "batch 144, gen_loss 0.920524,disc_loss 1.144919\n",
      "batch 145, gen_loss 0.922775,disc_loss 1.192177\n",
      "batch 146, gen_loss 0.941187,disc_loss 1.152842\n",
      "batch 147, gen_loss 0.908735,disc_loss 1.196539\n",
      "batch 148, gen_loss 0.938644,disc_loss 1.173679\n",
      "batch 149, gen_loss 0.912045,disc_loss 1.141693\n",
      "batch 150, gen_loss 0.927073,disc_loss 1.192172\n",
      "batch 151, gen_loss 0.894724,disc_loss 1.193865\n",
      "batch 152, gen_loss 0.911564,disc_loss 1.167385\n",
      "batch 153, gen_loss 0.863432,disc_loss 1.206986\n",
      "batch 154, gen_loss 0.898954,disc_loss 1.112557\n",
      "batch 155, gen_loss 0.895611,disc_loss 1.197933\n",
      "batch 156, gen_loss 0.906833,disc_loss 1.156745\n",
      "batch 157, gen_loss 0.933794,disc_loss 1.163679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 158, gen_loss 0.913808,disc_loss 1.163197\n",
      "batch 159, gen_loss 0.907725,disc_loss 1.176331\n",
      "batch 160, gen_loss 0.923348,disc_loss 1.174541\n",
      "batch 161, gen_loss 0.918418,disc_loss 1.175645\n",
      "batch 162, gen_loss 0.911241,disc_loss 1.153488\n",
      "batch 163, gen_loss 0.856122,disc_loss 1.222234\n",
      "batch 164, gen_loss 0.861102,disc_loss 1.189053\n",
      "batch 165, gen_loss 0.881304,disc_loss 1.196266\n",
      "batch 166, gen_loss 0.861989,disc_loss 1.201803\n",
      "batch 167, gen_loss 0.890562,disc_loss 1.186942\n",
      "batch 168, gen_loss 0.877133,disc_loss 1.186264\n",
      "batch 169, gen_loss 0.881027,disc_loss 1.194292\n",
      "batch 170, gen_loss 0.878915,disc_loss 1.209756\n",
      "batch 171, gen_loss 0.862336,disc_loss 1.214691\n",
      "batch 172, gen_loss 0.872365,disc_loss 1.214049\n",
      "batch 173, gen_loss 0.879212,disc_loss 1.227222\n",
      "batch 174, gen_loss 0.871576,disc_loss 1.223983\n",
      "batch 175, gen_loss 0.829491,disc_loss 1.263459\n",
      "batch 176, gen_loss 0.809666,disc_loss 1.265036\n",
      "batch 177, gen_loss 0.825117,disc_loss 1.240953\n",
      "batch 178, gen_loss 0.835720,disc_loss 1.212796\n",
      "batch 179, gen_loss 0.830450,disc_loss 1.250468\n",
      "batch 180, gen_loss 0.822490,disc_loss 1.243142\n",
      "batch 181, gen_loss 0.841791,disc_loss 1.243330\n",
      "batch 182, gen_loss 0.856394,disc_loss 1.269773\n",
      "batch 183, gen_loss 0.830420,disc_loss 1.270200\n",
      "batch 184, gen_loss 0.834821,disc_loss 1.237535\n",
      "batch 185, gen_loss 0.803467,disc_loss 1.228389\n",
      "batch 186, gen_loss 0.804404,disc_loss 1.261667\n",
      "batch 187, gen_loss 0.807810,disc_loss 1.319036\n",
      "batch 188, gen_loss 0.796938,disc_loss 1.267972\n",
      "batch 189, gen_loss 0.784797,disc_loss 1.312507\n",
      "batch 190, gen_loss 0.785001,disc_loss 1.328629\n",
      "batch 191, gen_loss 0.803643,disc_loss 1.310838\n",
      "batch 192, gen_loss 0.761184,disc_loss 1.315070\n",
      "batch 193, gen_loss 0.758296,disc_loss 1.307917\n",
      "batch 194, gen_loss 0.768885,disc_loss 1.318007\n",
      "batch 195, gen_loss 0.787890,disc_loss 1.289756\n",
      "batch 196, gen_loss 0.772001,disc_loss 1.363549\n",
      "batch 197, gen_loss 0.788831,disc_loss 1.297142\n",
      "batch 198, gen_loss 0.781933,disc_loss 1.330432\n",
      "batch 199, gen_loss 0.777679,disc_loss 1.332587\n",
      "batch 200, gen_loss 0.780765,disc_loss 1.324268\n",
      "batch 201, gen_loss 0.749253,disc_loss 1.356152\n",
      "batch 202, gen_loss 0.775499,disc_loss 1.334042\n",
      "batch 203, gen_loss 0.759295,disc_loss 1.347120\n",
      "batch 204, gen_loss 0.801613,disc_loss 1.292536\n",
      "batch 205, gen_loss 0.769103,disc_loss 1.331969\n",
      "batch 206, gen_loss 0.765529,disc_loss 1.318539\n",
      "batch 207, gen_loss 0.752820,disc_loss 1.322563\n",
      "batch 208, gen_loss 0.756236,disc_loss 1.282349\n",
      "batch 209, gen_loss 0.778722,disc_loss 1.314821\n",
      "batch 210, gen_loss 0.792116,disc_loss 1.298563\n",
      "batch 211, gen_loss 0.796007,disc_loss 1.291473\n",
      "batch 212, gen_loss 0.813284,disc_loss 1.310266\n",
      "batch 213, gen_loss 0.813004,disc_loss 1.292808\n",
      "batch 214, gen_loss 0.807901,disc_loss 1.268346\n",
      "batch 215, gen_loss 0.830386,disc_loss 1.252337\n",
      "batch 216, gen_loss 0.813773,disc_loss 1.269680\n",
      "batch 217, gen_loss 0.810170,disc_loss 1.240779\n",
      "batch 218, gen_loss 0.806680,disc_loss 1.263380\n",
      "batch 219, gen_loss 0.790197,disc_loss 1.227139\n",
      "batch 220, gen_loss 0.822019,disc_loss 1.206409\n",
      "batch 221, gen_loss 0.851304,disc_loss 1.211442\n",
      "batch 222, gen_loss 0.832114,disc_loss 1.213656\n",
      "batch 223, gen_loss 0.871292,disc_loss 1.221484\n",
      "batch 224, gen_loss 0.878743,disc_loss 1.197780\n",
      "batch 225, gen_loss 0.904917,disc_loss 1.202202\n",
      "batch 226, gen_loss 0.860753,disc_loss 1.202025\n",
      "batch 227, gen_loss 0.865096,disc_loss 1.206918\n",
      "batch 228, gen_loss 0.835273,disc_loss 1.198989\n",
      "batch 229, gen_loss 0.844971,disc_loss 1.179155\n",
      "batch 230, gen_loss 0.859352,disc_loss 1.187992\n",
      "batch 231, gen_loss 0.870077,disc_loss 1.210629\n",
      "batch 232, gen_loss 0.893933,disc_loss 1.217319\n",
      "batch 233, gen_loss 0.898211,disc_loss 1.248252\n",
      "batch 234, gen_loss 0.873702,disc_loss 1.163246\n",
      "batch 0, gen_loss 0.843980,disc_loss 1.206804\n",
      "batch 1, gen_loss 0.876871,disc_loss 1.209738\n",
      "batch 2, gen_loss 0.831544,disc_loss 1.239567\n",
      "batch 3, gen_loss 0.835242,disc_loss 1.196727\n",
      "batch 4, gen_loss 0.861216,disc_loss 1.284608\n",
      "batch 5, gen_loss 0.853852,disc_loss 1.239134\n",
      "batch 6, gen_loss 0.881432,disc_loss 1.230551\n",
      "batch 7, gen_loss 0.852513,disc_loss 1.242376\n",
      "batch 8, gen_loss 0.862549,disc_loss 1.269648\n",
      "batch 9, gen_loss 0.868703,disc_loss 1.241966\n",
      "batch 10, gen_loss 0.837657,disc_loss 1.284736\n",
      "batch 11, gen_loss 0.823608,disc_loss 1.271034\n",
      "batch 12, gen_loss 0.876996,disc_loss 1.248123\n",
      "batch 13, gen_loss 0.854830,disc_loss 1.253659\n",
      "batch 14, gen_loss 0.846144,disc_loss 1.245098\n",
      "batch 15, gen_loss 0.857384,disc_loss 1.291956\n",
      "batch 16, gen_loss 0.874619,disc_loss 1.284362\n",
      "batch 17, gen_loss 0.829465,disc_loss 1.313903\n",
      "batch 18, gen_loss 0.830425,disc_loss 1.308448\n",
      "batch 19, gen_loss 0.844184,disc_loss 1.252605\n",
      "batch 20, gen_loss 0.843652,disc_loss 1.248541\n",
      "batch 21, gen_loss 0.851666,disc_loss 1.249795\n",
      "batch 22, gen_loss 0.853055,disc_loss 1.273489\n",
      "batch 23, gen_loss 0.883821,disc_loss 1.231092\n",
      "batch 24, gen_loss 0.892784,disc_loss 1.219455\n",
      "batch 25, gen_loss 0.902798,disc_loss 1.247300\n",
      "batch 26, gen_loss 0.884492,disc_loss 1.236929\n",
      "batch 27, gen_loss 0.846569,disc_loss 1.259452\n",
      "batch 28, gen_loss 0.867499,disc_loss 1.218506\n",
      "batch 29, gen_loss 0.864792,disc_loss 1.207963\n",
      "batch 30, gen_loss 0.852395,disc_loss 1.212749\n",
      "batch 31, gen_loss 0.863137,disc_loss 1.264251\n",
      "batch 32, gen_loss 0.894389,disc_loss 1.174792\n",
      "batch 33, gen_loss 0.932557,disc_loss 1.153602\n",
      "batch 34, gen_loss 0.943412,disc_loss 1.235927\n",
      "batch 35, gen_loss 0.949990,disc_loss 1.154672\n",
      "batch 36, gen_loss 0.920746,disc_loss 1.167477\n",
      "batch 37, gen_loss 0.913301,disc_loss 1.166462\n",
      "batch 38, gen_loss 0.957798,disc_loss 1.121838\n",
      "batch 39, gen_loss 0.906319,disc_loss 1.102976\n",
      "batch 40, gen_loss 0.917685,disc_loss 1.132326\n",
      "batch 41, gen_loss 0.951291,disc_loss 1.123238\n",
      "batch 42, gen_loss 0.972774,disc_loss 1.074725\n",
      "batch 43, gen_loss 0.981024,disc_loss 1.057361\n",
      "batch 44, gen_loss 1.027370,disc_loss 1.056834\n",
      "batch 45, gen_loss 1.015401,disc_loss 1.060487\n",
      "batch 46, gen_loss 1.010905,disc_loss 1.029245\n",
      "batch 47, gen_loss 0.983825,disc_loss 1.037479\n",
      "batch 48, gen_loss 0.996237,disc_loss 1.003870\n",
      "batch 49, gen_loss 1.024542,disc_loss 1.030655\n",
      "batch 50, gen_loss 1.025320,disc_loss 1.002279\n",
      "batch 51, gen_loss 1.043243,disc_loss 0.972816\n",
      "batch 52, gen_loss 1.067068,disc_loss 0.979460\n",
      "batch 53, gen_loss 1.079313,disc_loss 0.961350\n",
      "batch 54, gen_loss 1.106831,disc_loss 0.966039\n",
      "batch 55, gen_loss 1.133915,disc_loss 0.902579\n",
      "batch 56, gen_loss 1.136344,disc_loss 0.933709\n",
      "batch 57, gen_loss 1.093569,disc_loss 0.927815\n",
      "batch 58, gen_loss 1.082098,disc_loss 0.898577\n",
      "batch 59, gen_loss 1.114888,disc_loss 0.901274\n",
      "batch 60, gen_loss 1.122433,disc_loss 0.892207\n",
      "batch 61, gen_loss 1.150913,disc_loss 0.910262\n",
      "batch 62, gen_loss 1.204332,disc_loss 0.892664\n",
      "batch 63, gen_loss 1.214972,disc_loss 0.868557\n",
      "batch 64, gen_loss 1.176701,disc_loss 0.880814\n",
      "batch 65, gen_loss 1.176009,disc_loss 0.862317\n",
      "batch 66, gen_loss 1.174066,disc_loss 0.878215\n",
      "batch 67, gen_loss 1.167777,disc_loss 0.846275\n",
      "batch 68, gen_loss 1.175250,disc_loss 0.833437\n",
      "batch 69, gen_loss 1.223862,disc_loss 0.858751\n",
      "batch 70, gen_loss 1.236169,disc_loss 0.869347\n",
      "batch 71, gen_loss 1.299524,disc_loss 0.883976\n",
      "batch 72, gen_loss 1.230346,disc_loss 0.907011\n",
      "batch 73, gen_loss 1.197584,disc_loss 0.933663\n",
      "batch 74, gen_loss 1.143024,disc_loss 0.902710\n",
      "batch 75, gen_loss 1.152017,disc_loss 0.898956\n",
      "batch 76, gen_loss 1.189415,disc_loss 0.907798\n",
      "batch 77, gen_loss 1.220667,disc_loss 0.916538\n",
      "batch 78, gen_loss 1.284702,disc_loss 0.891647\n",
      "batch 79, gen_loss 1.285490,disc_loss 0.964276\n",
      "batch 80, gen_loss 1.280655,disc_loss 0.964862\n",
      "batch 81, gen_loss 1.236017,disc_loss 0.989285\n",
      "batch 82, gen_loss 1.165524,disc_loss 0.979937\n",
      "batch 83, gen_loss 1.122659,disc_loss 1.059822\n",
      "batch 84, gen_loss 1.088532,disc_loss 1.015846\n",
      "batch 85, gen_loss 1.134513,disc_loss 1.097426\n",
      "batch 86, gen_loss 1.095976,disc_loss 1.105397\n",
      "batch 87, gen_loss 1.273671,disc_loss 1.131691\n",
      "batch 88, gen_loss 1.213172,disc_loss 1.126995\n",
      "batch 89, gen_loss 1.146789,disc_loss 1.157661\n",
      "batch 90, gen_loss 1.048428,disc_loss 1.160331\n",
      "batch 91, gen_loss 0.994012,disc_loss 1.233819\n",
      "batch 92, gen_loss 0.967023,disc_loss 1.272149\n",
      "batch 93, gen_loss 1.001308,disc_loss 1.313140\n",
      "batch 94, gen_loss 0.974921,disc_loss 1.352982\n",
      "batch 95, gen_loss 1.009135,disc_loss 1.298422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 96, gen_loss 1.024952,disc_loss 1.365139\n",
      "batch 97, gen_loss 0.999838,disc_loss 1.395730\n",
      "batch 98, gen_loss 0.848704,disc_loss 1.467855\n",
      "batch 99, gen_loss 0.815579,disc_loss 1.472310\n",
      "batch 100, gen_loss 0.823936,disc_loss 1.450240\n",
      "batch 101, gen_loss 0.816649,disc_loss 1.513019\n",
      "batch 102, gen_loss 0.821685,disc_loss 1.606321\n",
      "batch 103, gen_loss 0.821131,disc_loss 1.493696\n",
      "batch 104, gen_loss 0.853068,disc_loss 1.549946\n",
      "batch 105, gen_loss 0.780238,disc_loss 1.611247\n",
      "batch 106, gen_loss 0.745467,disc_loss 1.610263\n",
      "batch 107, gen_loss 0.759376,disc_loss 1.600048\n",
      "batch 108, gen_loss 0.662101,disc_loss 1.663433\n",
      "batch 109, gen_loss 0.661321,disc_loss 1.606719\n",
      "batch 110, gen_loss 0.711721,disc_loss 1.717780\n",
      "batch 111, gen_loss 0.725024,disc_loss 1.689469\n",
      "batch 112, gen_loss 0.678485,disc_loss 1.683775\n",
      "batch 113, gen_loss 0.688631,disc_loss 1.646808\n",
      "batch 114, gen_loss 0.679314,disc_loss 1.653378\n",
      "batch 115, gen_loss 0.678056,disc_loss 1.655366\n",
      "batch 116, gen_loss 0.645987,disc_loss 1.765717\n",
      "batch 117, gen_loss 0.605501,disc_loss 1.713409\n",
      "batch 118, gen_loss 0.632663,disc_loss 1.745164\n",
      "batch 119, gen_loss 0.628932,disc_loss 1.634321\n",
      "batch 120, gen_loss 0.597846,disc_loss 1.769535\n",
      "batch 121, gen_loss 0.629037,disc_loss 1.635966\n",
      "batch 122, gen_loss 0.612150,disc_loss 1.662598\n",
      "batch 123, gen_loss 0.611530,disc_loss 1.703122\n",
      "batch 124, gen_loss 0.643720,disc_loss 1.635179\n",
      "batch 125, gen_loss 0.641515,disc_loss 1.599291\n",
      "batch 126, gen_loss 0.641270,disc_loss 1.576822\n",
      "batch 127, gen_loss 0.641237,disc_loss 1.543453\n",
      "batch 128, gen_loss 0.688721,disc_loss 1.502462\n",
      "batch 129, gen_loss 0.677753,disc_loss 1.442202\n",
      "batch 130, gen_loss 0.703420,disc_loss 1.463390\n",
      "batch 131, gen_loss 0.721189,disc_loss 1.395089\n",
      "batch 132, gen_loss 0.706162,disc_loss 1.396002\n",
      "batch 133, gen_loss 0.763332,disc_loss 1.331408\n",
      "batch 134, gen_loss 0.773866,disc_loss 1.314396\n",
      "batch 135, gen_loss 0.772956,disc_loss 1.270867\n",
      "batch 136, gen_loss 0.802926,disc_loss 1.226285\n",
      "batch 137, gen_loss 0.807799,disc_loss 1.213318\n",
      "batch 138, gen_loss 0.837139,disc_loss 1.176239\n",
      "batch 139, gen_loss 0.818710,disc_loss 1.174651\n",
      "batch 140, gen_loss 0.872972,disc_loss 1.130572\n",
      "batch 141, gen_loss 0.958363,disc_loss 1.076249\n",
      "batch 142, gen_loss 0.965851,disc_loss 1.101364\n",
      "batch 143, gen_loss 0.983916,disc_loss 1.039422\n",
      "batch 144, gen_loss 0.968931,disc_loss 1.059119\n",
      "batch 145, gen_loss 1.026518,disc_loss 0.990244\n",
      "batch 146, gen_loss 1.038319,disc_loss 0.983105\n",
      "batch 147, gen_loss 1.080141,disc_loss 0.960783\n",
      "batch 148, gen_loss 1.059599,disc_loss 1.014029\n",
      "batch 149, gen_loss 1.095725,disc_loss 0.949347\n",
      "batch 150, gen_loss 1.097022,disc_loss 0.958845\n",
      "batch 151, gen_loss 1.089176,disc_loss 0.932784\n",
      "batch 152, gen_loss 1.103099,disc_loss 0.925404\n",
      "batch 153, gen_loss 1.130688,disc_loss 0.929934\n",
      "batch 154, gen_loss 1.075763,disc_loss 1.014187\n",
      "batch 155, gen_loss 1.106750,disc_loss 0.978352\n",
      "batch 156, gen_loss 1.113647,disc_loss 0.999352\n",
      "batch 157, gen_loss 1.125999,disc_loss 0.950104\n",
      "batch 158, gen_loss 1.128597,disc_loss 1.018791\n",
      "batch 159, gen_loss 1.102924,disc_loss 0.966274\n",
      "batch 160, gen_loss 1.050012,disc_loss 1.024781\n",
      "batch 161, gen_loss 1.046399,disc_loss 1.051084\n",
      "batch 162, gen_loss 1.049057,disc_loss 1.091949\n",
      "batch 163, gen_loss 1.094381,disc_loss 1.074434\n",
      "batch 164, gen_loss 1.089741,disc_loss 1.090539\n",
      "batch 165, gen_loss 1.066106,disc_loss 1.097502\n",
      "batch 166, gen_loss 1.046563,disc_loss 1.215656\n",
      "batch 167, gen_loss 0.988168,disc_loss 1.197559\n",
      "batch 168, gen_loss 1.002845,disc_loss 1.136942\n",
      "batch 169, gen_loss 0.979002,disc_loss 1.155912\n",
      "batch 170, gen_loss 0.948469,disc_loss 1.182778\n",
      "batch 171, gen_loss 0.978872,disc_loss 1.245377\n",
      "batch 172, gen_loss 0.955385,disc_loss 1.277878\n",
      "batch 173, gen_loss 0.958871,disc_loss 1.295526\n",
      "batch 174, gen_loss 0.988221,disc_loss 1.287172\n",
      "batch 175, gen_loss 0.961896,disc_loss 1.280625\n",
      "batch 176, gen_loss 0.850052,disc_loss 1.299596\n",
      "batch 177, gen_loss 0.871303,disc_loss 1.393774\n",
      "batch 178, gen_loss 0.865454,disc_loss 1.311232\n",
      "batch 179, gen_loss 0.875717,disc_loss 1.284684\n",
      "batch 180, gen_loss 0.956815,disc_loss 1.255114\n",
      "batch 181, gen_loss 0.924948,disc_loss 1.316689\n",
      "batch 182, gen_loss 0.880104,disc_loss 1.337329\n",
      "batch 183, gen_loss 0.938282,disc_loss 1.260371\n",
      "batch 184, gen_loss 0.878007,disc_loss 1.380267\n",
      "batch 185, gen_loss 0.833022,disc_loss 1.322201\n",
      "batch 186, gen_loss 0.841035,disc_loss 1.347898\n",
      "batch 187, gen_loss 0.852569,disc_loss 1.326302\n",
      "batch 188, gen_loss 0.876675,disc_loss 1.296799\n",
      "batch 189, gen_loss 0.894794,disc_loss 1.328999\n",
      "batch 190, gen_loss 0.866121,disc_loss 1.371709\n",
      "batch 191, gen_loss 0.904710,disc_loss 1.298579\n",
      "batch 192, gen_loss 0.884392,disc_loss 1.274695\n",
      "batch 193, gen_loss 0.887456,disc_loss 1.246091\n",
      "batch 194, gen_loss 0.904389,disc_loss 1.247280\n",
      "batch 195, gen_loss 0.910449,disc_loss 1.212634\n",
      "batch 196, gen_loss 0.932319,disc_loss 1.189539\n",
      "batch 197, gen_loss 0.958912,disc_loss 1.172450\n",
      "batch 198, gen_loss 0.933327,disc_loss 1.179573\n",
      "batch 199, gen_loss 0.928604,disc_loss 1.171327\n",
      "batch 200, gen_loss 0.953533,disc_loss 1.207869\n",
      "batch 201, gen_loss 0.977587,disc_loss 1.143589\n",
      "batch 202, gen_loss 0.960691,disc_loss 1.111270\n",
      "batch 203, gen_loss 0.982247,disc_loss 1.110539\n",
      "batch 204, gen_loss 1.013042,disc_loss 1.055289\n",
      "batch 205, gen_loss 1.005253,disc_loss 1.049500\n",
      "batch 206, gen_loss 0.997953,disc_loss 1.046486\n",
      "batch 207, gen_loss 1.027098,disc_loss 0.997626\n",
      "batch 208, gen_loss 1.041949,disc_loss 1.039233\n",
      "batch 209, gen_loss 1.080984,disc_loss 0.945574\n",
      "batch 210, gen_loss 1.087011,disc_loss 0.980802\n",
      "batch 211, gen_loss 1.106219,disc_loss 0.917970\n",
      "batch 212, gen_loss 1.119239,disc_loss 0.939490\n",
      "batch 213, gen_loss 1.155817,disc_loss 0.964441\n",
      "batch 214, gen_loss 1.145655,disc_loss 0.940767\n",
      "batch 215, gen_loss 1.121414,disc_loss 0.890882\n",
      "batch 216, gen_loss 1.131629,disc_loss 0.870522\n",
      "batch 217, gen_loss 1.125845,disc_loss 0.891720\n",
      "batch 218, gen_loss 1.155593,disc_loss 0.863351\n",
      "batch 219, gen_loss 1.222575,disc_loss 0.883525\n",
      "batch 220, gen_loss 1.185633,disc_loss 0.869684\n",
      "batch 221, gen_loss 1.228466,disc_loss 0.831523\n",
      "batch 222, gen_loss 1.175086,disc_loss 0.880338\n",
      "batch 223, gen_loss 1.160593,disc_loss 0.860120\n",
      "batch 224, gen_loss 1.184589,disc_loss 0.829374\n",
      "batch 225, gen_loss 1.200229,disc_loss 0.856230\n",
      "batch 226, gen_loss 1.208611,disc_loss 0.865043\n",
      "batch 227, gen_loss 1.220572,disc_loss 0.847488\n",
      "batch 228, gen_loss 1.283684,disc_loss 0.830832\n",
      "batch 229, gen_loss 1.246553,disc_loss 0.868500\n",
      "batch 230, gen_loss 1.203196,disc_loss 0.898872\n",
      "batch 231, gen_loss 1.180751,disc_loss 0.877558\n",
      "batch 232, gen_loss 1.133376,disc_loss 0.887221\n",
      "batch 233, gen_loss 1.132952,disc_loss 0.859311\n",
      "batch 234, gen_loss 1.218729,disc_loss 0.932927\n",
      "batch 0, gen_loss 1.164827,disc_loss 0.971824\n",
      "batch 1, gen_loss 1.216228,disc_loss 0.889001\n",
      "batch 2, gen_loss 1.172717,disc_loss 0.968644\n",
      "batch 3, gen_loss 1.088235,disc_loss 1.031550\n",
      "batch 4, gen_loss 1.057261,disc_loss 1.003094\n",
      "batch 5, gen_loss 1.000512,disc_loss 0.987194\n",
      "batch 6, gen_loss 1.036014,disc_loss 0.998467\n",
      "batch 7, gen_loss 1.140397,disc_loss 1.067870\n",
      "batch 8, gen_loss 1.159478,disc_loss 1.099857\n",
      "batch 9, gen_loss 1.107699,disc_loss 1.134720\n",
      "batch 10, gen_loss 1.000126,disc_loss 1.150229\n",
      "batch 11, gen_loss 0.914061,disc_loss 1.176403\n",
      "batch 12, gen_loss 0.902948,disc_loss 1.156487\n",
      "batch 13, gen_loss 0.880867,disc_loss 1.191044\n",
      "batch 14, gen_loss 0.945573,disc_loss 1.316066\n",
      "batch 15, gen_loss 1.062202,disc_loss 1.245086\n",
      "batch 16, gen_loss 0.977132,disc_loss 1.306004\n",
      "batch 17, gen_loss 0.877756,disc_loss 1.397077\n",
      "batch 18, gen_loss 0.751052,disc_loss 1.374895\n",
      "batch 19, gen_loss 0.718178,disc_loss 1.398619\n",
      "batch 20, gen_loss 0.746640,disc_loss 1.358968\n",
      "batch 21, gen_loss 0.891470,disc_loss 1.387177\n",
      "batch 22, gen_loss 0.986546,disc_loss 1.350901\n",
      "batch 23, gen_loss 0.965290,disc_loss 1.436064\n",
      "batch 24, gen_loss 0.873598,disc_loss 1.410323\n",
      "batch 25, gen_loss 0.788656,disc_loss 1.359513\n",
      "batch 26, gen_loss 0.725759,disc_loss 1.362384\n",
      "batch 27, gen_loss 0.730476,disc_loss 1.385511\n",
      "batch 28, gen_loss 0.794435,disc_loss 1.347783\n",
      "batch 29, gen_loss 0.892980,disc_loss 1.314802\n",
      "batch 30, gen_loss 0.963039,disc_loss 1.391079\n",
      "batch 31, gen_loss 0.950144,disc_loss 1.328828\n",
      "batch 32, gen_loss 0.888564,disc_loss 1.336858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 33, gen_loss 0.856252,disc_loss 1.359955\n",
      "batch 34, gen_loss 0.773206,disc_loss 1.257116\n",
      "batch 35, gen_loss 0.781468,disc_loss 1.372501\n",
      "batch 36, gen_loss 0.802556,disc_loss 1.284829\n",
      "batch 37, gen_loss 0.875392,disc_loss 1.310252\n",
      "batch 38, gen_loss 0.921907,disc_loss 1.319588\n",
      "batch 39, gen_loss 0.963870,disc_loss 1.272413\n",
      "batch 40, gen_loss 0.922625,disc_loss 1.276669\n",
      "batch 41, gen_loss 0.851240,disc_loss 1.234659\n",
      "batch 42, gen_loss 0.867727,disc_loss 1.191303\n",
      "batch 43, gen_loss 0.894578,disc_loss 1.212909\n",
      "batch 44, gen_loss 0.927529,disc_loss 1.228317\n",
      "batch 45, gen_loss 0.942412,disc_loss 1.262264\n",
      "batch 46, gen_loss 0.982052,disc_loss 1.245545\n",
      "batch 47, gen_loss 0.952677,disc_loss 1.229975\n",
      "batch 48, gen_loss 0.945571,disc_loss 1.218031\n",
      "batch 49, gen_loss 0.888310,disc_loss 1.326503\n",
      "batch 50, gen_loss 0.904504,disc_loss 1.257640\n",
      "batch 51, gen_loss 0.856991,disc_loss 1.285142\n",
      "batch 52, gen_loss 0.876838,disc_loss 1.262820\n",
      "batch 53, gen_loss 0.907872,disc_loss 1.315666\n",
      "batch 54, gen_loss 0.962771,disc_loss 1.303127\n",
      "batch 55, gen_loss 0.948952,disc_loss 1.251922\n",
      "batch 56, gen_loss 0.954140,disc_loss 1.291147\n",
      "batch 57, gen_loss 0.898095,disc_loss 1.315466\n",
      "batch 58, gen_loss 0.895300,disc_loss 1.312003\n",
      "batch 59, gen_loss 0.889048,disc_loss 1.357995\n",
      "batch 60, gen_loss 0.821569,disc_loss 1.350386\n",
      "batch 61, gen_loss 0.864015,disc_loss 1.401015\n",
      "batch 62, gen_loss 0.850569,disc_loss 1.425897\n",
      "batch 63, gen_loss 0.876980,disc_loss 1.386571\n",
      "batch 64, gen_loss 0.845001,disc_loss 1.415248\n",
      "batch 65, gen_loss 0.895774,disc_loss 1.406268\n",
      "batch 66, gen_loss 0.815104,disc_loss 1.413672\n",
      "batch 67, gen_loss 0.810895,disc_loss 1.437615\n",
      "batch 68, gen_loss 0.803851,disc_loss 1.423784\n",
      "batch 69, gen_loss 0.884611,disc_loss 1.346274\n",
      "batch 70, gen_loss 0.849994,disc_loss 1.357444\n",
      "batch 71, gen_loss 0.896204,disc_loss 1.359303\n",
      "batch 72, gen_loss 0.864343,disc_loss 1.366889\n",
      "batch 73, gen_loss 0.897587,disc_loss 1.458846\n",
      "batch 74, gen_loss 0.856913,disc_loss 1.447391\n",
      "batch 75, gen_loss 0.870092,disc_loss 1.383660\n",
      "batch 76, gen_loss 0.832413,disc_loss 1.410282\n",
      "batch 77, gen_loss 0.845310,disc_loss 1.408774\n",
      "batch 78, gen_loss 0.823127,disc_loss 1.427082\n",
      "batch 79, gen_loss 0.809482,disc_loss 1.372059\n",
      "batch 80, gen_loss 0.822637,disc_loss 1.327103\n",
      "batch 81, gen_loss 0.871021,disc_loss 1.370258\n",
      "batch 82, gen_loss 0.905118,disc_loss 1.376430\n",
      "batch 83, gen_loss 0.848607,disc_loss 1.393791\n",
      "batch 84, gen_loss 0.932001,disc_loss 1.413668\n",
      "batch 85, gen_loss 0.906707,disc_loss 1.403745\n",
      "batch 86, gen_loss 0.907515,disc_loss 1.361218\n",
      "batch 87, gen_loss 0.889580,disc_loss 1.406606\n",
      "batch 88, gen_loss 0.834399,disc_loss 1.452941\n",
      "batch 89, gen_loss 0.847905,disc_loss 1.417961\n",
      "batch 90, gen_loss 0.858714,disc_loss 1.425879\n",
      "batch 91, gen_loss 0.822119,disc_loss 1.447795\n",
      "batch 92, gen_loss 0.844117,disc_loss 1.493468\n",
      "batch 93, gen_loss 0.885179,disc_loss 1.505159\n",
      "batch 94, gen_loss 0.910642,disc_loss 1.409882\n",
      "batch 95, gen_loss 0.933226,disc_loss 1.501530\n",
      "batch 96, gen_loss 0.870305,disc_loss 1.439853\n",
      "batch 97, gen_loss 0.854525,disc_loss 1.492302\n",
      "batch 98, gen_loss 0.834624,disc_loss 1.549405\n",
      "batch 99, gen_loss 0.860330,disc_loss 1.475899\n",
      "batch 100, gen_loss 0.814167,disc_loss 1.511056\n",
      "batch 101, gen_loss 0.829490,disc_loss 1.541043\n",
      "batch 102, gen_loss 0.886347,disc_loss 1.416633\n",
      "batch 103, gen_loss 0.932147,disc_loss 1.506661\n",
      "batch 104, gen_loss 0.893741,disc_loss 1.535730\n",
      "batch 105, gen_loss 0.940514,disc_loss 1.552632\n",
      "batch 106, gen_loss 0.877064,disc_loss 1.444001\n",
      "batch 107, gen_loss 0.876548,disc_loss 1.465201\n",
      "batch 108, gen_loss 0.895559,disc_loss 1.483726\n",
      "batch 109, gen_loss 0.846545,disc_loss 1.473986\n",
      "batch 110, gen_loss 0.885431,disc_loss 1.443885\n",
      "batch 111, gen_loss 0.868599,disc_loss 1.488819\n",
      "batch 112, gen_loss 0.909994,disc_loss 1.513377\n",
      "batch 113, gen_loss 0.966927,disc_loss 1.477276\n",
      "batch 114, gen_loss 0.991082,disc_loss 1.388743\n",
      "batch 115, gen_loss 0.949532,disc_loss 1.426273\n",
      "batch 116, gen_loss 0.964853,disc_loss 1.413589\n",
      "batch 117, gen_loss 0.949997,disc_loss 1.369007\n",
      "batch 118, gen_loss 0.920570,disc_loss 1.391134\n",
      "batch 119, gen_loss 0.920317,disc_loss 1.312070\n",
      "batch 120, gen_loss 0.953400,disc_loss 1.241236\n",
      "batch 121, gen_loss 1.025664,disc_loss 1.299457\n",
      "batch 122, gen_loss 1.050867,disc_loss 1.306848\n",
      "batch 123, gen_loss 1.010135,disc_loss 1.323496\n",
      "batch 124, gen_loss 0.995872,disc_loss 1.214312\n",
      "batch 125, gen_loss 1.000470,disc_loss 1.230158\n",
      "batch 126, gen_loss 1.006082,disc_loss 1.216568\n",
      "batch 127, gen_loss 0.996535,disc_loss 1.204448\n",
      "batch 128, gen_loss 1.007846,disc_loss 1.143366\n",
      "batch 129, gen_loss 1.014047,disc_loss 1.162282\n",
      "batch 130, gen_loss 1.043095,disc_loss 1.122182\n",
      "batch 131, gen_loss 1.065396,disc_loss 1.173376\n",
      "batch 132, gen_loss 1.052162,disc_loss 1.081299\n",
      "batch 133, gen_loss 1.068275,disc_loss 1.086373\n",
      "batch 134, gen_loss 1.086089,disc_loss 1.097040\n",
      "batch 135, gen_loss 1.065678,disc_loss 1.013079\n",
      "batch 136, gen_loss 1.020371,disc_loss 1.048966\n",
      "batch 137, gen_loss 1.016973,disc_loss 1.075539\n",
      "batch 138, gen_loss 1.071492,disc_loss 1.006777\n",
      "batch 139, gen_loss 1.108210,disc_loss 1.016676\n",
      "batch 140, gen_loss 1.117495,disc_loss 0.984154\n",
      "batch 141, gen_loss 1.120620,disc_loss 1.022704\n",
      "batch 142, gen_loss 1.077657,disc_loss 1.016463\n",
      "batch 143, gen_loss 1.102309,disc_loss 0.942321\n",
      "batch 144, gen_loss 1.090723,disc_loss 0.956532\n",
      "batch 145, gen_loss 1.133056,disc_loss 0.950102\n",
      "batch 146, gen_loss 1.129565,disc_loss 0.956861\n",
      "batch 147, gen_loss 1.168244,disc_loss 0.896070\n",
      "batch 148, gen_loss 1.166614,disc_loss 0.884535\n",
      "batch 149, gen_loss 1.151695,disc_loss 0.878593\n",
      "batch 150, gen_loss 1.153866,disc_loss 0.927864\n",
      "batch 151, gen_loss 1.195787,disc_loss 0.869811\n",
      "batch 152, gen_loss 1.181858,disc_loss 0.928751\n",
      "batch 153, gen_loss 1.195979,disc_loss 0.856053\n",
      "batch 154, gen_loss 1.180033,disc_loss 0.855913\n",
      "batch 155, gen_loss 1.199049,disc_loss 0.853554\n",
      "batch 156, gen_loss 1.206729,disc_loss 0.834176\n",
      "batch 157, gen_loss 1.190988,disc_loss 0.838370\n",
      "batch 158, gen_loss 1.231324,disc_loss 0.861341\n",
      "batch 159, gen_loss 1.306756,disc_loss 0.829335\n",
      "batch 160, gen_loss 1.275419,disc_loss 0.843438\n",
      "batch 161, gen_loss 1.252664,disc_loss 0.843055\n",
      "batch 162, gen_loss 1.292092,disc_loss 0.840009\n",
      "batch 163, gen_loss 1.209625,disc_loss 0.890319\n",
      "batch 164, gen_loss 1.236287,disc_loss 0.914636\n",
      "batch 165, gen_loss 1.197056,disc_loss 0.946911\n",
      "batch 166, gen_loss 1.156603,disc_loss 0.901692\n",
      "batch 167, gen_loss 1.161261,disc_loss 0.939008\n",
      "batch 168, gen_loss 1.246634,disc_loss 0.884037\n",
      "batch 169, gen_loss 1.286943,disc_loss 0.935100\n",
      "batch 170, gen_loss 1.233900,disc_loss 0.998675\n",
      "batch 171, gen_loss 1.239484,disc_loss 1.000579\n",
      "batch 172, gen_loss 1.214186,disc_loss 0.999610\n",
      "batch 173, gen_loss 1.135276,disc_loss 1.033720\n",
      "batch 174, gen_loss 1.121115,disc_loss 1.061894\n",
      "batch 175, gen_loss 1.109752,disc_loss 1.094948\n",
      "batch 176, gen_loss 1.160232,disc_loss 1.070036\n",
      "batch 177, gen_loss 1.110431,disc_loss 1.123479\n",
      "batch 178, gen_loss 1.052195,disc_loss 1.180323\n",
      "batch 179, gen_loss 0.978932,disc_loss 1.184276\n",
      "batch 180, gen_loss 1.008981,disc_loss 1.175543\n",
      "batch 181, gen_loss 1.059519,disc_loss 1.258343\n",
      "batch 182, gen_loss 1.037051,disc_loss 1.224996\n",
      "batch 183, gen_loss 1.052300,disc_loss 1.195593\n",
      "batch 184, gen_loss 1.105908,disc_loss 1.282629\n",
      "batch 185, gen_loss 1.049869,disc_loss 1.215214\n",
      "batch 186, gen_loss 1.006619,disc_loss 1.328874\n",
      "batch 187, gen_loss 1.014582,disc_loss 1.262253\n",
      "batch 188, gen_loss 0.953717,disc_loss 1.345420\n",
      "batch 189, gen_loss 0.869602,disc_loss 1.289316\n",
      "batch 190, gen_loss 0.957282,disc_loss 1.266139\n",
      "batch 191, gen_loss 0.929910,disc_loss 1.289861\n",
      "batch 192, gen_loss 1.016190,disc_loss 1.314263\n",
      "batch 193, gen_loss 1.014177,disc_loss 1.298450\n",
      "batch 194, gen_loss 1.024700,disc_loss 1.302127\n",
      "batch 195, gen_loss 0.947133,disc_loss 1.326429\n",
      "batch 196, gen_loss 0.998787,disc_loss 1.295795\n",
      "batch 197, gen_loss 0.951865,disc_loss 1.339748\n",
      "batch 198, gen_loss 0.918062,disc_loss 1.239889\n",
      "batch 199, gen_loss 0.898347,disc_loss 1.357982\n",
      "batch 200, gen_loss 0.907795,disc_loss 1.271269\n",
      "batch 201, gen_loss 0.965550,disc_loss 1.232567\n",
      "batch 202, gen_loss 1.000208,disc_loss 1.202636\n",
      "batch 203, gen_loss 1.007021,disc_loss 1.299379\n",
      "batch 204, gen_loss 1.058839,disc_loss 1.212361\n",
      "batch 205, gen_loss 1.002085,disc_loss 1.301947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 206, gen_loss 0.977970,disc_loss 1.292973\n",
      "batch 207, gen_loss 0.995838,disc_loss 1.212516\n",
      "batch 208, gen_loss 0.946892,disc_loss 1.253564\n",
      "batch 209, gen_loss 0.990430,disc_loss 1.234404\n",
      "batch 210, gen_loss 0.930559,disc_loss 1.174925\n",
      "batch 211, gen_loss 1.005737,disc_loss 1.162771\n",
      "batch 212, gen_loss 1.039607,disc_loss 1.212898\n",
      "batch 213, gen_loss 1.034029,disc_loss 1.191294\n",
      "batch 214, gen_loss 1.049926,disc_loss 1.152947\n",
      "batch 215, gen_loss 1.057914,disc_loss 1.178036\n",
      "batch 216, gen_loss 1.043846,disc_loss 1.164995\n",
      "batch 217, gen_loss 1.071169,disc_loss 1.081990\n",
      "batch 218, gen_loss 1.024156,disc_loss 1.072636\n",
      "batch 219, gen_loss 1.059772,disc_loss 1.084076\n",
      "batch 220, gen_loss 0.989559,disc_loss 1.036350\n",
      "batch 221, gen_loss 0.987633,disc_loss 1.105878\n",
      "batch 222, gen_loss 1.028837,disc_loss 1.011574\n",
      "batch 223, gen_loss 1.039551,disc_loss 1.079221\n",
      "batch 224, gen_loss 1.055391,disc_loss 1.088602\n",
      "batch 225, gen_loss 1.102632,disc_loss 1.014652\n",
      "batch 226, gen_loss 1.165065,disc_loss 1.022074\n",
      "batch 227, gen_loss 1.081767,disc_loss 1.028182\n",
      "batch 228, gen_loss 1.090040,disc_loss 1.000227\n",
      "batch 229, gen_loss 1.038749,disc_loss 1.039287\n",
      "batch 230, gen_loss 1.053245,disc_loss 1.002275\n",
      "batch 231, gen_loss 1.038065,disc_loss 0.979591\n",
      "batch 232, gen_loss 1.050191,disc_loss 0.956467\n",
      "batch 233, gen_loss 1.047163,disc_loss 0.999501\n",
      "batch 234, gen_loss 1.148921,disc_loss 0.930904\n",
      "batch 0, gen_loss 1.147902,disc_loss 0.972081\n",
      "batch 1, gen_loss 1.098755,disc_loss 1.013110\n",
      "batch 2, gen_loss 1.167292,disc_loss 0.985622\n",
      "batch 3, gen_loss 1.127389,disc_loss 0.984076\n",
      "batch 4, gen_loss 1.078546,disc_loss 0.978758\n",
      "batch 5, gen_loss 1.076274,disc_loss 0.985977\n",
      "batch 6, gen_loss 1.003992,disc_loss 1.031423\n",
      "batch 7, gen_loss 0.979944,disc_loss 1.049135\n",
      "batch 8, gen_loss 0.965644,disc_loss 1.130292\n",
      "batch 9, gen_loss 1.118589,disc_loss 1.038508\n",
      "batch 10, gen_loss 1.036828,disc_loss 1.092463\n",
      "batch 11, gen_loss 1.113388,disc_loss 1.055861\n",
      "batch 12, gen_loss 1.041495,disc_loss 1.128458\n",
      "batch 13, gen_loss 1.007905,disc_loss 1.151364\n",
      "batch 14, gen_loss 0.964588,disc_loss 1.176165\n",
      "batch 15, gen_loss 0.980192,disc_loss 1.257345\n",
      "batch 16, gen_loss 0.947241,disc_loss 1.293656\n",
      "batch 17, gen_loss 0.923650,disc_loss 1.271095\n",
      "batch 18, gen_loss 0.875418,disc_loss 1.274699\n",
      "batch 19, gen_loss 0.898648,disc_loss 1.355636\n",
      "batch 20, gen_loss 0.891977,disc_loss 1.375647\n",
      "batch 21, gen_loss 0.868362,disc_loss 1.376463\n",
      "batch 22, gen_loss 0.847842,disc_loss 1.388258\n",
      "batch 23, gen_loss 0.896066,disc_loss 1.400433\n",
      "batch 24, gen_loss 0.815758,disc_loss 1.502385\n",
      "batch 25, gen_loss 0.817477,disc_loss 1.455557\n",
      "batch 26, gen_loss 0.778970,disc_loss 1.548995\n",
      "batch 27, gen_loss 0.782272,disc_loss 1.528203\n",
      "batch 28, gen_loss 0.772908,disc_loss 1.626575\n",
      "batch 29, gen_loss 0.794032,disc_loss 1.526332\n",
      "batch 30, gen_loss 0.760915,disc_loss 1.577958\n",
      "batch 31, gen_loss 0.701131,disc_loss 1.597901\n",
      "batch 32, gen_loss 0.687012,disc_loss 1.651658\n",
      "batch 33, gen_loss 0.739230,disc_loss 1.545149\n",
      "batch 34, gen_loss 0.708877,disc_loss 1.653392\n",
      "batch 35, gen_loss 0.741043,disc_loss 1.604561\n",
      "batch 36, gen_loss 0.727255,disc_loss 1.578820\n",
      "batch 37, gen_loss 0.729466,disc_loss 1.577676\n",
      "batch 38, gen_loss 0.734148,disc_loss 1.630266\n",
      "batch 39, gen_loss 0.715250,disc_loss 1.565821\n",
      "batch 40, gen_loss 0.708649,disc_loss 1.616726\n",
      "batch 41, gen_loss 0.709589,disc_loss 1.626691\n",
      "batch 42, gen_loss 0.675362,disc_loss 1.612341\n",
      "batch 43, gen_loss 0.712564,disc_loss 1.599223\n",
      "batch 44, gen_loss 0.691375,disc_loss 1.627440\n",
      "batch 45, gen_loss 0.697479,disc_loss 1.645027\n",
      "batch 46, gen_loss 0.717233,disc_loss 1.526323\n",
      "batch 47, gen_loss 0.697736,disc_loss 1.598945\n",
      "batch 48, gen_loss 0.726924,disc_loss 1.560277\n",
      "batch 49, gen_loss 0.717029,disc_loss 1.494881\n",
      "batch 50, gen_loss 0.729683,disc_loss 1.480836\n",
      "batch 51, gen_loss 0.735134,disc_loss 1.532020\n",
      "batch 52, gen_loss 0.758940,disc_loss 1.478042\n",
      "batch 53, gen_loss 0.767366,disc_loss 1.395698\n",
      "batch 54, gen_loss 0.767033,disc_loss 1.356712\n",
      "batch 55, gen_loss 0.807073,disc_loss 1.338795\n",
      "batch 56, gen_loss 0.800012,disc_loss 1.429533\n",
      "batch 57, gen_loss 0.844604,disc_loss 1.290177\n",
      "batch 58, gen_loss 0.843577,disc_loss 1.258787\n",
      "batch 59, gen_loss 0.825630,disc_loss 1.328302\n",
      "batch 60, gen_loss 0.823492,disc_loss 1.270973\n",
      "batch 61, gen_loss 0.828978,disc_loss 1.253056\n",
      "batch 62, gen_loss 0.853050,disc_loss 1.260733\n",
      "batch 63, gen_loss 0.861554,disc_loss 1.239724\n",
      "batch 64, gen_loss 0.919859,disc_loss 1.146783\n",
      "batch 65, gen_loss 0.921812,disc_loss 1.185567\n",
      "batch 66, gen_loss 0.908736,disc_loss 1.123139\n",
      "batch 67, gen_loss 0.940886,disc_loss 1.082126\n",
      "batch 68, gen_loss 0.936145,disc_loss 1.119089\n",
      "batch 69, gen_loss 0.930693,disc_loss 1.106380\n",
      "batch 70, gen_loss 0.986127,disc_loss 1.104762\n",
      "batch 71, gen_loss 0.972535,disc_loss 1.101631\n",
      "batch 72, gen_loss 0.971656,disc_loss 1.046248\n",
      "batch 73, gen_loss 1.005456,disc_loss 1.053120\n",
      "batch 74, gen_loss 0.997177,disc_loss 1.054948\n",
      "batch 75, gen_loss 0.992067,disc_loss 1.029082\n",
      "batch 76, gen_loss 1.011356,disc_loss 1.034263\n",
      "batch 77, gen_loss 1.026821,disc_loss 1.056862\n",
      "batch 78, gen_loss 1.041552,disc_loss 0.993629\n",
      "batch 79, gen_loss 1.000936,disc_loss 1.025979\n",
      "batch 80, gen_loss 1.015386,disc_loss 1.015441\n",
      "batch 81, gen_loss 1.061707,disc_loss 1.005560\n",
      "batch 82, gen_loss 1.028715,disc_loss 1.006292\n",
      "batch 83, gen_loss 1.000077,disc_loss 1.021244\n",
      "batch 84, gen_loss 1.055417,disc_loss 0.977756\n",
      "batch 85, gen_loss 1.061608,disc_loss 0.966591\n",
      "batch 86, gen_loss 1.111680,disc_loss 0.938504\n",
      "batch 87, gen_loss 1.094374,disc_loss 0.935678\n",
      "batch 88, gen_loss 1.108846,disc_loss 0.940219\n",
      "batch 89, gen_loss 1.124257,disc_loss 0.924170\n",
      "batch 90, gen_loss 1.125682,disc_loss 0.887215\n",
      "batch 91, gen_loss 1.118088,disc_loss 0.909433\n",
      "batch 92, gen_loss 1.151171,disc_loss 0.896578\n",
      "batch 93, gen_loss 1.120297,disc_loss 0.883147\n",
      "batch 94, gen_loss 1.131839,disc_loss 0.925794\n",
      "batch 95, gen_loss 1.165973,disc_loss 0.877463\n",
      "batch 96, gen_loss 1.138344,disc_loss 0.875787\n",
      "batch 97, gen_loss 1.149813,disc_loss 0.909899\n",
      "batch 98, gen_loss 1.177438,disc_loss 0.863755\n",
      "batch 99, gen_loss 1.182572,disc_loss 0.839739\n",
      "batch 100, gen_loss 1.229419,disc_loss 0.837162\n",
      "batch 101, gen_loss 1.280591,disc_loss 0.836551\n",
      "batch 102, gen_loss 1.228448,disc_loss 0.865332\n",
      "batch 103, gen_loss 1.225408,disc_loss 0.818311\n",
      "batch 104, gen_loss 1.216828,disc_loss 0.828163\n",
      "batch 105, gen_loss 1.191316,disc_loss 0.809817\n",
      "batch 106, gen_loss 1.239929,disc_loss 0.813453\n",
      "batch 107, gen_loss 1.250278,disc_loss 0.857949\n",
      "batch 108, gen_loss 1.291219,disc_loss 0.841136\n",
      "batch 109, gen_loss 1.241065,disc_loss 0.842839\n",
      "batch 110, gen_loss 1.244967,disc_loss 0.825030\n",
      "batch 111, gen_loss 1.265921,disc_loss 0.874477\n",
      "batch 112, gen_loss 1.167910,disc_loss 0.881264\n",
      "batch 113, gen_loss 1.172408,disc_loss 0.863676\n",
      "batch 114, gen_loss 1.184039,disc_loss 0.907736\n",
      "batch 115, gen_loss 1.262924,disc_loss 0.877996\n",
      "batch 116, gen_loss 1.264859,disc_loss 0.896301\n",
      "batch 117, gen_loss 1.263966,disc_loss 0.890002\n",
      "batch 118, gen_loss 1.220001,disc_loss 0.917438\n",
      "batch 119, gen_loss 1.167055,disc_loss 0.989418\n",
      "batch 120, gen_loss 1.144287,disc_loss 0.924595\n",
      "batch 121, gen_loss 1.076992,disc_loss 0.939043\n",
      "batch 122, gen_loss 1.162478,disc_loss 0.936043\n",
      "batch 123, gen_loss 1.188964,disc_loss 0.925233\n",
      "batch 124, gen_loss 1.240832,disc_loss 0.980914\n",
      "batch 125, gen_loss 1.249159,disc_loss 0.984046\n",
      "batch 126, gen_loss 1.197020,disc_loss 0.987935\n",
      "batch 127, gen_loss 1.152579,disc_loss 1.000524\n",
      "batch 128, gen_loss 1.146980,disc_loss 0.977070\n",
      "batch 129, gen_loss 1.133632,disc_loss 0.984583\n",
      "batch 130, gen_loss 1.141456,disc_loss 0.951490\n",
      "batch 131, gen_loss 1.098511,disc_loss 1.029824\n",
      "batch 132, gen_loss 1.153103,disc_loss 1.086303\n",
      "batch 133, gen_loss 1.144299,disc_loss 1.010615\n",
      "batch 134, gen_loss 1.177188,disc_loss 0.997837\n",
      "batch 135, gen_loss 1.131506,disc_loss 1.021420\n",
      "batch 136, gen_loss 1.099940,disc_loss 1.035884\n",
      "batch 137, gen_loss 1.102587,disc_loss 1.009316\n",
      "batch 138, gen_loss 1.131027,disc_loss 1.049395\n",
      "batch 139, gen_loss 1.100801,disc_loss 1.064115\n",
      "batch 140, gen_loss 1.161420,disc_loss 1.097609\n",
      "batch 141, gen_loss 1.126768,disc_loss 0.996054\n",
      "batch 142, gen_loss 1.137630,disc_loss 1.007934\n",
      "batch 143, gen_loss 1.072691,disc_loss 1.016416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 144, gen_loss 1.035405,disc_loss 1.042865\n",
      "batch 145, gen_loss 1.114310,disc_loss 1.046490\n",
      "batch 146, gen_loss 1.105657,disc_loss 1.090906\n",
      "batch 147, gen_loss 1.122795,disc_loss 1.073029\n",
      "batch 148, gen_loss 1.037965,disc_loss 1.054491\n",
      "batch 149, gen_loss 1.122458,disc_loss 1.075497\n",
      "batch 150, gen_loss 1.045445,disc_loss 1.091452\n",
      "batch 151, gen_loss 1.083142,disc_loss 1.056868\n",
      "batch 152, gen_loss 1.005975,disc_loss 1.169007\n",
      "batch 153, gen_loss 1.045535,disc_loss 1.103892\n",
      "batch 154, gen_loss 1.013845,disc_loss 1.140804\n",
      "batch 155, gen_loss 0.994638,disc_loss 1.195987\n",
      "batch 156, gen_loss 1.058196,disc_loss 1.170587\n",
      "batch 157, gen_loss 1.002997,disc_loss 1.214299\n",
      "batch 158, gen_loss 0.911556,disc_loss 1.298405\n",
      "batch 159, gen_loss 0.840694,disc_loss 1.307180\n",
      "batch 160, gen_loss 0.896623,disc_loss 1.325787\n",
      "batch 161, gen_loss 0.920536,disc_loss 1.351020\n",
      "batch 162, gen_loss 0.935970,disc_loss 1.332460\n",
      "batch 163, gen_loss 0.918811,disc_loss 1.477403\n",
      "batch 164, gen_loss 0.868942,disc_loss 1.381223\n",
      "batch 165, gen_loss 0.826699,disc_loss 1.414766\n",
      "batch 166, gen_loss 0.794282,disc_loss 1.520393\n",
      "batch 167, gen_loss 0.800794,disc_loss 1.497360\n",
      "batch 168, gen_loss 0.817535,disc_loss 1.526476\n",
      "batch 169, gen_loss 0.803718,disc_loss 1.570328\n",
      "batch 170, gen_loss 0.791673,disc_loss 1.650509\n",
      "batch 171, gen_loss 0.780024,disc_loss 1.583342\n",
      "batch 172, gen_loss 0.791655,disc_loss 1.487523\n",
      "batch 173, gen_loss 0.713931,disc_loss 1.605498\n",
      "batch 174, gen_loss 0.708769,disc_loss 1.665139\n",
      "batch 175, gen_loss 0.731559,disc_loss 1.555594\n",
      "batch 176, gen_loss 0.769626,disc_loss 1.502206\n",
      "batch 177, gen_loss 0.805442,disc_loss 1.484239\n",
      "batch 178, gen_loss 0.789730,disc_loss 1.539034\n",
      "batch 179, gen_loss 0.744589,disc_loss 1.534106\n",
      "batch 180, gen_loss 0.783204,disc_loss 1.457225\n",
      "batch 181, gen_loss 0.754860,disc_loss 1.457685\n",
      "batch 182, gen_loss 0.757389,disc_loss 1.415859\n",
      "batch 183, gen_loss 0.796443,disc_loss 1.384162\n",
      "batch 184, gen_loss 0.789078,disc_loss 1.386849\n",
      "batch 185, gen_loss 0.850305,disc_loss 1.349061\n",
      "batch 186, gen_loss 0.901590,disc_loss 1.262663\n",
      "batch 187, gen_loss 0.942780,disc_loss 1.230237\n",
      "batch 188, gen_loss 0.946139,disc_loss 1.167270\n",
      "batch 189, gen_loss 0.978342,disc_loss 1.169013\n",
      "batch 190, gen_loss 0.986609,disc_loss 1.096088\n",
      "batch 191, gen_loss 1.004436,disc_loss 1.060035\n",
      "batch 192, gen_loss 1.077662,disc_loss 1.071007\n",
      "batch 193, gen_loss 1.068213,disc_loss 1.028697\n",
      "batch 194, gen_loss 1.141466,disc_loss 1.002591\n",
      "batch 195, gen_loss 1.146493,disc_loss 0.950133\n",
      "batch 196, gen_loss 1.170460,disc_loss 0.916993\n",
      "batch 197, gen_loss 1.229416,disc_loss 0.902595\n",
      "batch 198, gen_loss 1.272668,disc_loss 0.900976\n",
      "batch 199, gen_loss 1.260366,disc_loss 0.890266\n",
      "batch 200, gen_loss 1.231703,disc_loss 0.864188\n",
      "batch 201, gen_loss 1.238523,disc_loss 0.893913\n",
      "batch 202, gen_loss 1.259085,disc_loss 0.869243\n",
      "batch 203, gen_loss 1.278990,disc_loss 0.864818\n",
      "batch 204, gen_loss 1.251963,disc_loss 0.924689\n",
      "batch 205, gen_loss 1.323987,disc_loss 0.878099\n",
      "batch 206, gen_loss 1.256572,disc_loss 0.922998\n",
      "batch 207, gen_loss 1.309985,disc_loss 0.905960\n",
      "batch 208, gen_loss 1.231090,disc_loss 0.940953\n",
      "batch 209, gen_loss 1.267738,disc_loss 0.904337\n",
      "batch 210, gen_loss 1.260329,disc_loss 0.904826\n",
      "batch 211, gen_loss 1.247656,disc_loss 0.950973\n",
      "batch 212, gen_loss 1.251007,disc_loss 0.995553\n",
      "batch 213, gen_loss 1.192872,disc_loss 1.000714\n",
      "batch 214, gen_loss 1.163469,disc_loss 1.041368\n",
      "batch 215, gen_loss 1.217992,disc_loss 1.121076\n",
      "batch 216, gen_loss 1.205359,disc_loss 1.123372\n",
      "batch 217, gen_loss 1.125795,disc_loss 1.207750\n",
      "batch 218, gen_loss 1.107384,disc_loss 1.168272\n",
      "batch 219, gen_loss 1.022918,disc_loss 1.178021\n",
      "batch 220, gen_loss 1.091948,disc_loss 1.252918\n",
      "batch 221, gen_loss 1.060212,disc_loss 1.305550\n",
      "batch 222, gen_loss 1.044021,disc_loss 1.303834\n",
      "batch 223, gen_loss 1.023309,disc_loss 1.315662\n",
      "batch 224, gen_loss 0.998649,disc_loss 1.424170\n",
      "batch 225, gen_loss 0.964288,disc_loss 1.407050\n",
      "batch 226, gen_loss 0.922842,disc_loss 1.367184\n",
      "batch 227, gen_loss 0.917640,disc_loss 1.410515\n",
      "batch 228, gen_loss 0.921814,disc_loss 1.435700\n",
      "batch 229, gen_loss 0.949205,disc_loss 1.511404\n",
      "batch 230, gen_loss 0.933951,disc_loss 1.441589\n",
      "batch 231, gen_loss 0.900304,disc_loss 1.412389\n",
      "batch 232, gen_loss 0.858615,disc_loss 1.498370\n",
      "batch 233, gen_loss 0.858400,disc_loss 1.351538\n",
      "batch 234, gen_loss 0.848128,disc_loss 1.427547\n",
      "batch 0, gen_loss 0.874630,disc_loss 1.450380\n",
      "batch 1, gen_loss 0.901330,disc_loss 1.448862\n",
      "batch 2, gen_loss 0.902229,disc_loss 1.451510\n",
      "batch 3, gen_loss 0.890630,disc_loss 1.408080\n",
      "batch 4, gen_loss 0.872260,disc_loss 1.314218\n",
      "batch 5, gen_loss 0.839183,disc_loss 1.418481\n",
      "batch 6, gen_loss 0.805163,disc_loss 1.430027\n",
      "batch 7, gen_loss 0.876871,disc_loss 1.382105\n",
      "batch 8, gen_loss 0.909210,disc_loss 1.365056\n",
      "batch 9, gen_loss 0.906895,disc_loss 1.398708\n",
      "batch 10, gen_loss 0.911991,disc_loss 1.393099\n",
      "batch 11, gen_loss 0.843907,disc_loss 1.309294\n",
      "batch 12, gen_loss 0.875506,disc_loss 1.305125\n",
      "batch 13, gen_loss 0.886743,disc_loss 1.220990\n",
      "batch 14, gen_loss 0.878035,disc_loss 1.318003\n",
      "batch 15, gen_loss 0.889693,disc_loss 1.250790\n",
      "batch 16, gen_loss 0.937438,disc_loss 1.275066\n",
      "batch 17, gen_loss 0.971014,disc_loss 1.178689\n",
      "batch 18, gen_loss 1.011802,disc_loss 1.189634\n",
      "batch 19, gen_loss 0.970882,disc_loss 1.194559\n",
      "batch 20, gen_loss 0.927928,disc_loss 1.167641\n",
      "batch 21, gen_loss 0.914478,disc_loss 1.192333\n",
      "batch 22, gen_loss 0.931408,disc_loss 1.152792\n",
      "batch 23, gen_loss 0.969571,disc_loss 1.191075\n",
      "batch 24, gen_loss 0.998970,disc_loss 1.138056\n",
      "batch 25, gen_loss 1.012479,disc_loss 1.123118\n",
      "batch 26, gen_loss 1.013083,disc_loss 1.097095\n",
      "batch 27, gen_loss 1.070536,disc_loss 1.054653\n",
      "batch 28, gen_loss 1.031853,disc_loss 1.144530\n",
      "batch 29, gen_loss 0.998731,disc_loss 1.125477\n",
      "batch 30, gen_loss 0.965718,disc_loss 1.120683\n",
      "batch 31, gen_loss 1.014452,disc_loss 1.087799\n",
      "batch 32, gen_loss 1.001778,disc_loss 1.110259\n",
      "batch 33, gen_loss 1.019657,disc_loss 1.130708\n",
      "batch 34, gen_loss 1.028531,disc_loss 1.123772\n",
      "batch 35, gen_loss 1.018077,disc_loss 1.108196\n",
      "batch 36, gen_loss 1.025032,disc_loss 1.122237\n",
      "batch 37, gen_loss 0.983330,disc_loss 1.086311\n",
      "batch 38, gen_loss 0.991661,disc_loss 1.096356\n",
      "batch 39, gen_loss 0.970353,disc_loss 1.114240\n",
      "batch 40, gen_loss 1.020069,disc_loss 1.107183\n",
      "batch 41, gen_loss 1.052018,disc_loss 1.140143\n",
      "batch 42, gen_loss 1.036242,disc_loss 1.122229\n",
      "batch 43, gen_loss 1.032863,disc_loss 1.084533\n",
      "batch 44, gen_loss 1.012995,disc_loss 1.130092\n",
      "batch 45, gen_loss 0.996466,disc_loss 1.103511\n",
      "batch 46, gen_loss 0.988067,disc_loss 1.107455\n",
      "batch 47, gen_loss 0.999803,disc_loss 1.129043\n",
      "batch 48, gen_loss 1.000150,disc_loss 1.172402\n",
      "batch 49, gen_loss 0.963439,disc_loss 1.158234\n",
      "batch 50, gen_loss 0.982407,disc_loss 1.175275\n",
      "batch 51, gen_loss 0.985306,disc_loss 1.130768\n",
      "batch 52, gen_loss 1.038487,disc_loss 1.116056\n",
      "batch 53, gen_loss 0.997013,disc_loss 1.145898\n",
      "batch 54, gen_loss 0.940547,disc_loss 1.158610\n",
      "batch 55, gen_loss 0.989524,disc_loss 1.143007\n",
      "batch 56, gen_loss 0.978912,disc_loss 1.174169\n",
      "batch 57, gen_loss 0.901268,disc_loss 1.214658\n",
      "batch 58, gen_loss 0.906491,disc_loss 1.123631\n",
      "batch 59, gen_loss 0.918682,disc_loss 1.193746\n",
      "batch 60, gen_loss 0.968133,disc_loss 1.186232\n",
      "batch 61, gen_loss 0.977199,disc_loss 1.196410\n",
      "batch 62, gen_loss 0.976635,disc_loss 1.176221\n",
      "batch 63, gen_loss 0.905193,disc_loss 1.228353\n",
      "batch 64, gen_loss 0.933262,disc_loss 1.191797\n",
      "batch 65, gen_loss 0.952559,disc_loss 1.143942\n",
      "batch 66, gen_loss 0.905323,disc_loss 1.192966\n",
      "batch 67, gen_loss 0.911264,disc_loss 1.173654\n",
      "batch 68, gen_loss 0.878573,disc_loss 1.247736\n",
      "batch 69, gen_loss 0.943491,disc_loss 1.186920\n",
      "batch 70, gen_loss 0.972460,disc_loss 1.157003\n",
      "batch 71, gen_loss 0.935011,disc_loss 1.154338\n",
      "batch 72, gen_loss 0.935789,disc_loss 1.147449\n",
      "batch 73, gen_loss 0.940279,disc_loss 1.165971\n",
      "batch 74, gen_loss 0.978185,disc_loss 1.115593\n",
      "batch 75, gen_loss 0.933676,disc_loss 1.171444\n",
      "batch 76, gen_loss 0.938359,disc_loss 1.163735\n",
      "batch 77, gen_loss 0.949499,disc_loss 1.109945\n",
      "batch 78, gen_loss 0.915865,disc_loss 1.138954\n",
      "batch 79, gen_loss 0.937740,disc_loss 1.077951\n",
      "batch 80, gen_loss 0.991605,disc_loss 1.101095\n",
      "batch 81, gen_loss 0.951602,disc_loss 1.170817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 82, gen_loss 0.982475,disc_loss 1.110144\n",
      "batch 83, gen_loss 0.998014,disc_loss 1.072436\n",
      "batch 84, gen_loss 0.997838,disc_loss 1.105365\n",
      "batch 85, gen_loss 0.994901,disc_loss 1.031587\n",
      "batch 86, gen_loss 0.961032,disc_loss 1.090998\n",
      "batch 87, gen_loss 0.997613,disc_loss 1.085986\n",
      "batch 88, gen_loss 0.988350,disc_loss 1.064018\n",
      "batch 89, gen_loss 1.001651,disc_loss 1.076654\n",
      "batch 90, gen_loss 1.027261,disc_loss 1.020578\n",
      "batch 91, gen_loss 1.018559,disc_loss 1.019033\n",
      "batch 92, gen_loss 0.990454,disc_loss 1.042636\n",
      "batch 93, gen_loss 1.040120,disc_loss 1.002717\n",
      "batch 94, gen_loss 1.061231,disc_loss 1.012924\n",
      "batch 95, gen_loss 1.087672,disc_loss 1.023182\n",
      "batch 96, gen_loss 1.082993,disc_loss 1.045740\n",
      "batch 97, gen_loss 1.064118,disc_loss 0.980693\n",
      "batch 98, gen_loss 0.992215,disc_loss 0.975581\n",
      "batch 99, gen_loss 1.090753,disc_loss 0.975920\n",
      "batch 100, gen_loss 1.122752,disc_loss 0.925693\n",
      "batch 101, gen_loss 1.103030,disc_loss 0.942630\n",
      "batch 102, gen_loss 1.168638,disc_loss 0.933727\n",
      "batch 103, gen_loss 1.077113,disc_loss 0.944204\n",
      "batch 104, gen_loss 1.142085,disc_loss 0.942482\n",
      "batch 105, gen_loss 1.213456,disc_loss 0.900970\n",
      "batch 106, gen_loss 1.160123,disc_loss 0.912893\n",
      "batch 107, gen_loss 1.154473,disc_loss 0.903173\n",
      "batch 108, gen_loss 1.167084,disc_loss 0.913355\n",
      "batch 109, gen_loss 1.114877,disc_loss 0.898752\n",
      "batch 110, gen_loss 1.148463,disc_loss 0.911955\n",
      "batch 111, gen_loss 1.203088,disc_loss 0.900580\n",
      "batch 112, gen_loss 1.217373,disc_loss 0.861573\n",
      "batch 113, gen_loss 1.220167,disc_loss 0.860823\n",
      "batch 114, gen_loss 1.189151,disc_loss 0.862242\n",
      "batch 115, gen_loss 1.236801,disc_loss 0.882752\n",
      "batch 116, gen_loss 1.235172,disc_loss 0.874796\n",
      "batch 117, gen_loss 1.253989,disc_loss 0.845441\n",
      "batch 118, gen_loss 1.232098,disc_loss 0.888300\n",
      "batch 119, gen_loss 1.274921,disc_loss 0.787640\n",
      "batch 120, gen_loss 1.284749,disc_loss 0.836215\n",
      "batch 121, gen_loss 1.328258,disc_loss 0.849905\n",
      "batch 122, gen_loss 1.238566,disc_loss 0.908522\n",
      "batch 123, gen_loss 1.287105,disc_loss 0.860817\n",
      "batch 124, gen_loss 1.223192,disc_loss 0.910221\n",
      "batch 125, gen_loss 1.186373,disc_loss 0.892875\n",
      "batch 126, gen_loss 1.180256,disc_loss 0.872417\n",
      "batch 127, gen_loss 1.161855,disc_loss 0.909752\n",
      "batch 128, gen_loss 1.286292,disc_loss 0.962844\n",
      "batch 129, gen_loss 1.263891,disc_loss 0.894620\n",
      "batch 130, gen_loss 1.281695,disc_loss 0.936026\n",
      "batch 131, gen_loss 1.164686,disc_loss 0.968685\n",
      "batch 132, gen_loss 1.184601,disc_loss 0.915297\n",
      "batch 133, gen_loss 1.095878,disc_loss 0.976006\n",
      "batch 134, gen_loss 1.127522,disc_loss 0.983169\n",
      "batch 135, gen_loss 1.117512,disc_loss 1.047657\n",
      "batch 136, gen_loss 1.135355,disc_loss 1.062322\n",
      "batch 137, gen_loss 1.109594,disc_loss 1.086726\n",
      "batch 138, gen_loss 1.023159,disc_loss 1.119143\n",
      "batch 139, gen_loss 0.996637,disc_loss 1.069531\n",
      "batch 140, gen_loss 0.956842,disc_loss 1.121896\n",
      "batch 141, gen_loss 1.052977,disc_loss 1.147008\n",
      "batch 142, gen_loss 1.080142,disc_loss 1.185815\n",
      "batch 143, gen_loss 0.994490,disc_loss 1.224500\n",
      "batch 144, gen_loss 0.984056,disc_loss 1.248615\n",
      "batch 145, gen_loss 0.907627,disc_loss 1.295931\n",
      "batch 146, gen_loss 0.886149,disc_loss 1.313842\n",
      "batch 147, gen_loss 0.843748,disc_loss 1.322252\n",
      "batch 148, gen_loss 0.919378,disc_loss 1.357040\n",
      "batch 149, gen_loss 0.901103,disc_loss 1.417555\n",
      "batch 150, gen_loss 0.834755,disc_loss 1.455932\n",
      "batch 151, gen_loss 0.851877,disc_loss 1.388609\n",
      "batch 152, gen_loss 0.766084,disc_loss 1.473131\n",
      "batch 153, gen_loss 0.779119,disc_loss 1.476187\n",
      "batch 154, gen_loss 0.769729,disc_loss 1.547719\n",
      "batch 155, gen_loss 0.753065,disc_loss 1.554451\n",
      "batch 156, gen_loss 0.767486,disc_loss 1.570417\n",
      "batch 157, gen_loss 0.795090,disc_loss 1.580062\n",
      "batch 158, gen_loss 0.741859,disc_loss 1.636849\n",
      "batch 159, gen_loss 0.718579,disc_loss 1.631992\n",
      "batch 160, gen_loss 0.668982,disc_loss 1.659465\n",
      "batch 161, gen_loss 0.680440,disc_loss 1.679383\n",
      "batch 162, gen_loss 0.695406,disc_loss 1.662414\n",
      "batch 163, gen_loss 0.703482,disc_loss 1.676893\n",
      "batch 164, gen_loss 0.668215,disc_loss 1.708678\n",
      "batch 165, gen_loss 0.703119,disc_loss 1.681832\n",
      "batch 166, gen_loss 0.703631,disc_loss 1.655948\n",
      "batch 167, gen_loss 0.643644,disc_loss 1.646667\n",
      "batch 168, gen_loss 0.669960,disc_loss 1.669710\n",
      "batch 169, gen_loss 0.694272,disc_loss 1.659222\n",
      "batch 170, gen_loss 0.705510,disc_loss 1.654355\n",
      "batch 171, gen_loss 0.695665,disc_loss 1.722832\n",
      "batch 172, gen_loss 0.656951,disc_loss 1.691721\n",
      "batch 173, gen_loss 0.657094,disc_loss 1.662150\n",
      "batch 174, gen_loss 0.678182,disc_loss 1.605630\n",
      "batch 175, gen_loss 0.695752,disc_loss 1.581959\n",
      "batch 176, gen_loss 0.733385,disc_loss 1.567180\n",
      "batch 177, gen_loss 0.728400,disc_loss 1.600020\n",
      "batch 178, gen_loss 0.734063,disc_loss 1.575837\n",
      "batch 179, gen_loss 0.699616,disc_loss 1.572590\n",
      "batch 180, gen_loss 0.713735,disc_loss 1.522052\n",
      "batch 181, gen_loss 0.746232,disc_loss 1.490588\n",
      "batch 182, gen_loss 0.731644,disc_loss 1.478561\n",
      "batch 183, gen_loss 0.771763,disc_loss 1.475243\n",
      "batch 184, gen_loss 0.744665,disc_loss 1.474721\n",
      "batch 185, gen_loss 0.758093,disc_loss 1.494063\n",
      "batch 186, gen_loss 0.743903,disc_loss 1.438723\n",
      "batch 187, gen_loss 0.745871,disc_loss 1.386982\n",
      "batch 188, gen_loss 0.783983,disc_loss 1.366367\n",
      "batch 189, gen_loss 0.843520,disc_loss 1.369244\n",
      "batch 190, gen_loss 0.825151,disc_loss 1.381640\n",
      "batch 191, gen_loss 0.863334,disc_loss 1.379189\n",
      "batch 192, gen_loss 0.827083,disc_loss 1.358693\n",
      "batch 193, gen_loss 0.820935,disc_loss 1.337983\n",
      "batch 194, gen_loss 0.800625,disc_loss 1.323676\n",
      "batch 195, gen_loss 0.808490,disc_loss 1.297471\n",
      "batch 196, gen_loss 0.845677,disc_loss 1.337337\n",
      "batch 197, gen_loss 0.860664,disc_loss 1.286076\n",
      "batch 198, gen_loss 0.872568,disc_loss 1.253259\n",
      "batch 199, gen_loss 0.899401,disc_loss 1.237073\n",
      "batch 200, gen_loss 0.904084,disc_loss 1.272266\n",
      "batch 201, gen_loss 0.916010,disc_loss 1.248052\n",
      "batch 202, gen_loss 0.909324,disc_loss 1.237144\n",
      "batch 203, gen_loss 0.899389,disc_loss 1.242227\n",
      "batch 204, gen_loss 0.873161,disc_loss 1.199911\n",
      "batch 205, gen_loss 0.898207,disc_loss 1.258893\n",
      "batch 206, gen_loss 0.881669,disc_loss 1.217691\n",
      "batch 207, gen_loss 0.944681,disc_loss 1.196461\n",
      "batch 208, gen_loss 0.961465,disc_loss 1.197285\n",
      "batch 209, gen_loss 0.952237,disc_loss 1.177601\n",
      "batch 210, gen_loss 0.980131,disc_loss 1.148134\n",
      "batch 211, gen_loss 0.921947,disc_loss 1.222333\n",
      "batch 212, gen_loss 0.907161,disc_loss 1.206599\n",
      "batch 213, gen_loss 0.943640,disc_loss 1.162081\n",
      "batch 214, gen_loss 0.881820,disc_loss 1.201025\n",
      "batch 215, gen_loss 0.957312,disc_loss 1.126389\n",
      "batch 216, gen_loss 0.973821,disc_loss 1.121294\n",
      "batch 217, gen_loss 0.980144,disc_loss 1.130033\n",
      "batch 218, gen_loss 0.957294,disc_loss 1.188467\n",
      "batch 219, gen_loss 0.993473,disc_loss 1.129917\n",
      "batch 220, gen_loss 0.999922,disc_loss 1.172812\n",
      "batch 221, gen_loss 1.002156,disc_loss 1.134057\n",
      "batch 222, gen_loss 1.009850,disc_loss 1.063110\n",
      "batch 223, gen_loss 0.948964,disc_loss 1.121271\n",
      "batch 224, gen_loss 0.995232,disc_loss 1.085062\n",
      "batch 225, gen_loss 1.010966,disc_loss 1.066397\n",
      "batch 226, gen_loss 1.027932,disc_loss 1.055447\n",
      "batch 227, gen_loss 1.073653,disc_loss 1.050240\n",
      "batch 228, gen_loss 1.058444,disc_loss 1.062733\n",
      "batch 229, gen_loss 1.080518,disc_loss 1.080300\n",
      "batch 230, gen_loss 1.056830,disc_loss 1.031159\n",
      "batch 231, gen_loss 1.060781,disc_loss 1.003556\n",
      "batch 232, gen_loss 1.024071,disc_loss 1.086625\n",
      "batch 233, gen_loss 1.066974,disc_loss 0.965625\n",
      "batch 234, gen_loss 1.106382,disc_loss 0.956468\n",
      "batch 0, gen_loss 1.130376,disc_loss 0.928633\n",
      "batch 1, gen_loss 1.123249,disc_loss 0.987694\n",
      "batch 2, gen_loss 1.138785,disc_loss 0.958577\n",
      "batch 3, gen_loss 1.213895,disc_loss 0.912743\n",
      "batch 4, gen_loss 1.196618,disc_loss 0.940036\n",
      "batch 5, gen_loss 1.123384,disc_loss 0.950904\n",
      "batch 6, gen_loss 1.150500,disc_loss 0.893340\n",
      "batch 7, gen_loss 1.115234,disc_loss 0.903347\n",
      "batch 8, gen_loss 1.159496,disc_loss 0.896548\n",
      "batch 9, gen_loss 1.223385,disc_loss 0.898478\n",
      "batch 10, gen_loss 1.188679,disc_loss 0.896530\n",
      "batch 11, gen_loss 1.242703,disc_loss 0.899882\n",
      "batch 12, gen_loss 1.254728,disc_loss 0.859850\n",
      "batch 13, gen_loss 1.278085,disc_loss 0.856334\n",
      "batch 14, gen_loss 1.217232,disc_loss 0.866627\n",
      "batch 15, gen_loss 1.250610,disc_loss 0.848481\n",
      "batch 16, gen_loss 1.167913,disc_loss 0.856223\n",
      "batch 17, gen_loss 1.138845,disc_loss 0.839455\n",
      "batch 18, gen_loss 1.206253,disc_loss 0.839877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 19, gen_loss 1.273812,disc_loss 0.876566\n",
      "batch 20, gen_loss 1.286346,disc_loss 0.839807\n",
      "batch 21, gen_loss 1.330826,disc_loss 0.820199\n",
      "batch 22, gen_loss 1.283190,disc_loss 0.878987\n",
      "batch 23, gen_loss 1.209597,disc_loss 0.904794\n",
      "batch 24, gen_loss 1.213423,disc_loss 0.848412\n",
      "batch 25, gen_loss 1.212972,disc_loss 0.848438\n",
      "batch 26, gen_loss 1.210261,disc_loss 0.896409\n",
      "batch 27, gen_loss 1.170178,disc_loss 0.924719\n",
      "batch 28, gen_loss 1.153788,disc_loss 0.883196\n",
      "batch 29, gen_loss 1.156747,disc_loss 0.936986\n",
      "batch 30, gen_loss 1.201455,disc_loss 0.987407\n",
      "batch 31, gen_loss 1.177197,disc_loss 0.920257\n",
      "batch 32, gen_loss 1.155915,disc_loss 0.974470\n",
      "batch 33, gen_loss 1.135793,disc_loss 1.017876\n",
      "batch 34, gen_loss 1.082351,disc_loss 1.019510\n",
      "batch 35, gen_loss 1.031072,disc_loss 1.081482\n",
      "batch 36, gen_loss 1.007469,disc_loss 1.028579\n",
      "batch 37, gen_loss 0.964138,disc_loss 1.114344\n",
      "batch 38, gen_loss 1.060633,disc_loss 1.053610\n",
      "batch 39, gen_loss 1.023469,disc_loss 1.187617\n",
      "batch 40, gen_loss 1.001840,disc_loss 1.195973\n",
      "batch 41, gen_loss 0.999678,disc_loss 1.167597\n",
      "batch 42, gen_loss 0.923721,disc_loss 1.205544\n",
      "batch 43, gen_loss 0.934381,disc_loss 1.248752\n",
      "batch 44, gen_loss 0.827780,disc_loss 1.315923\n",
      "batch 45, gen_loss 0.862290,disc_loss 1.271195\n",
      "batch 46, gen_loss 0.835409,disc_loss 1.269849\n",
      "batch 47, gen_loss 0.854502,disc_loss 1.383515\n",
      "batch 48, gen_loss 0.895364,disc_loss 1.369505\n",
      "batch 49, gen_loss 0.851842,disc_loss 1.317873\n",
      "batch 50, gen_loss 0.856140,disc_loss 1.313324\n",
      "batch 51, gen_loss 0.845878,disc_loss 1.334174\n",
      "batch 52, gen_loss 0.829484,disc_loss 1.407155\n",
      "batch 53, gen_loss 0.876341,disc_loss 1.369291\n",
      "batch 54, gen_loss 0.849650,disc_loss 1.333442\n",
      "batch 55, gen_loss 0.818296,disc_loss 1.366573\n",
      "batch 56, gen_loss 0.855000,disc_loss 1.283127\n",
      "batch 57, gen_loss 0.864615,disc_loss 1.270602\n",
      "batch 58, gen_loss 0.920189,disc_loss 1.301174\n",
      "batch 59, gen_loss 0.852102,disc_loss 1.275577\n",
      "batch 60, gen_loss 0.874780,disc_loss 1.273994\n",
      "batch 61, gen_loss 0.895610,disc_loss 1.275919\n",
      "batch 62, gen_loss 0.964976,disc_loss 1.254565\n",
      "batch 63, gen_loss 0.895709,disc_loss 1.300637\n",
      "batch 64, gen_loss 0.924459,disc_loss 1.312881\n",
      "batch 65, gen_loss 0.948783,disc_loss 1.285715\n",
      "batch 66, gen_loss 0.912741,disc_loss 1.243462\n",
      "batch 67, gen_loss 0.923496,disc_loss 1.212610\n",
      "batch 68, gen_loss 0.916201,disc_loss 1.220957\n",
      "batch 69, gen_loss 1.001175,disc_loss 1.131461\n",
      "batch 70, gen_loss 0.994661,disc_loss 1.263548\n",
      "batch 71, gen_loss 1.036261,disc_loss 1.230286\n",
      "batch 72, gen_loss 1.035110,disc_loss 1.195368\n",
      "batch 73, gen_loss 0.917136,disc_loss 1.240443\n",
      "batch 74, gen_loss 0.946546,disc_loss 1.221531\n",
      "batch 75, gen_loss 0.942111,disc_loss 1.275282\n",
      "batch 76, gen_loss 0.927092,disc_loss 1.239247\n",
      "batch 77, gen_loss 0.964285,disc_loss 1.192233\n",
      "batch 78, gen_loss 1.025914,disc_loss 1.218156\n",
      "batch 79, gen_loss 1.028756,disc_loss 1.226416\n",
      "batch 80, gen_loss 1.055255,disc_loss 1.294094\n",
      "batch 81, gen_loss 1.005729,disc_loss 1.258288\n",
      "batch 82, gen_loss 0.904139,disc_loss 1.380371\n",
      "batch 83, gen_loss 0.915258,disc_loss 1.245263\n",
      "batch 84, gen_loss 0.934715,disc_loss 1.338106\n",
      "batch 85, gen_loss 0.942075,disc_loss 1.272984\n",
      "batch 86, gen_loss 0.926734,disc_loss 1.324707\n",
      "batch 87, gen_loss 1.003020,disc_loss 1.263847\n",
      "batch 88, gen_loss 1.001487,disc_loss 1.224391\n",
      "batch 89, gen_loss 1.047745,disc_loss 1.248518\n",
      "batch 90, gen_loss 1.055952,disc_loss 1.210499\n",
      "batch 91, gen_loss 0.967167,disc_loss 1.259548\n",
      "batch 92, gen_loss 0.973055,disc_loss 1.292114\n",
      "batch 93, gen_loss 0.913021,disc_loss 1.307412\n",
      "batch 94, gen_loss 0.969864,disc_loss 1.329998\n",
      "batch 95, gen_loss 0.974462,disc_loss 1.224514\n",
      "batch 96, gen_loss 1.004190,disc_loss 1.208878\n",
      "batch 97, gen_loss 1.059518,disc_loss 1.168967\n",
      "batch 98, gen_loss 1.033074,disc_loss 1.241828\n",
      "batch 99, gen_loss 0.991708,disc_loss 1.270258\n",
      "batch 100, gen_loss 1.030884,disc_loss 1.246586\n",
      "batch 101, gen_loss 1.070141,disc_loss 1.163502\n",
      "batch 102, gen_loss 1.081816,disc_loss 1.171418\n",
      "batch 103, gen_loss 1.075379,disc_loss 1.103009\n",
      "batch 104, gen_loss 1.028400,disc_loss 1.125311\n",
      "batch 105, gen_loss 1.095927,disc_loss 1.104076\n",
      "batch 106, gen_loss 1.063483,disc_loss 1.173362\n",
      "batch 107, gen_loss 1.158573,disc_loss 1.092472\n",
      "batch 108, gen_loss 1.120985,disc_loss 1.086380\n",
      "batch 109, gen_loss 1.102608,disc_loss 1.060787\n",
      "batch 110, gen_loss 1.045830,disc_loss 1.100350\n",
      "batch 111, gen_loss 1.095801,disc_loss 1.064451\n",
      "batch 112, gen_loss 1.146894,disc_loss 1.040184\n",
      "batch 113, gen_loss 1.200423,disc_loss 1.039154\n",
      "batch 114, gen_loss 1.186136,disc_loss 1.058443\n",
      "batch 115, gen_loss 1.153952,disc_loss 1.029952\n",
      "batch 116, gen_loss 1.151654,disc_loss 0.993851\n",
      "batch 117, gen_loss 1.165851,disc_loss 1.010464\n",
      "batch 118, gen_loss 1.122727,disc_loss 0.982318\n",
      "batch 119, gen_loss 1.152201,disc_loss 1.080815\n",
      "batch 120, gen_loss 1.194767,disc_loss 1.045522\n",
      "batch 121, gen_loss 1.231930,disc_loss 1.089618\n",
      "batch 122, gen_loss 1.164690,disc_loss 1.047178\n",
      "batch 123, gen_loss 1.210811,disc_loss 1.034210\n",
      "batch 124, gen_loss 1.077240,disc_loss 1.141727\n",
      "batch 125, gen_loss 1.112261,disc_loss 1.106498\n",
      "batch 126, gen_loss 1.082955,disc_loss 1.105187\n",
      "batch 127, gen_loss 1.102031,disc_loss 1.097249\n",
      "batch 128, gen_loss 1.168122,disc_loss 1.104549\n",
      "batch 129, gen_loss 1.103324,disc_loss 1.174340\n",
      "batch 130, gen_loss 1.118731,disc_loss 1.183089\n",
      "batch 131, gen_loss 1.026312,disc_loss 1.175166\n",
      "batch 132, gen_loss 1.035227,disc_loss 1.186975\n",
      "batch 133, gen_loss 0.960889,disc_loss 1.268152\n",
      "batch 134, gen_loss 0.986609,disc_loss 1.235104\n",
      "batch 135, gen_loss 1.040607,disc_loss 1.299715\n",
      "batch 136, gen_loss 0.995600,disc_loss 1.230708\n",
      "batch 137, gen_loss 0.960024,disc_loss 1.293837\n",
      "batch 138, gen_loss 0.925515,disc_loss 1.291618\n",
      "batch 139, gen_loss 0.958526,disc_loss 1.328882\n",
      "batch 140, gen_loss 0.958645,disc_loss 1.309279\n",
      "batch 141, gen_loss 0.844901,disc_loss 1.336412\n",
      "batch 142, gen_loss 0.876961,disc_loss 1.292118\n",
      "batch 143, gen_loss 0.908337,disc_loss 1.372371\n",
      "batch 144, gen_loss 0.872707,disc_loss 1.333997\n",
      "batch 145, gen_loss 0.910221,disc_loss 1.345493\n",
      "batch 146, gen_loss 0.934388,disc_loss 1.325267\n",
      "batch 147, gen_loss 0.893172,disc_loss 1.312974\n",
      "batch 148, gen_loss 0.844702,disc_loss 1.357127\n",
      "batch 149, gen_loss 0.849460,disc_loss 1.369793\n",
      "batch 150, gen_loss 0.857257,disc_loss 1.342577\n",
      "batch 151, gen_loss 0.841991,disc_loss 1.352830\n",
      "batch 152, gen_loss 0.857544,disc_loss 1.341739\n",
      "batch 153, gen_loss 0.856948,disc_loss 1.334311\n",
      "batch 154, gen_loss 0.851655,disc_loss 1.382978\n",
      "batch 155, gen_loss 0.842979,disc_loss 1.408506\n",
      "batch 156, gen_loss 0.798400,disc_loss 1.447459\n",
      "batch 157, gen_loss 0.800135,disc_loss 1.410626\n",
      "batch 158, gen_loss 0.788540,disc_loss 1.349925\n",
      "batch 159, gen_loss 0.824353,disc_loss 1.408277\n",
      "batch 160, gen_loss 0.820481,disc_loss 1.403904\n",
      "batch 161, gen_loss 0.800385,disc_loss 1.365160\n",
      "batch 162, gen_loss 0.840582,disc_loss 1.254963\n",
      "batch 163, gen_loss 0.809422,disc_loss 1.319309\n",
      "batch 164, gen_loss 0.898789,disc_loss 1.284440\n",
      "batch 165, gen_loss 0.920439,disc_loss 1.246598\n",
      "batch 166, gen_loss 0.892560,disc_loss 1.293110\n",
      "batch 167, gen_loss 0.879057,disc_loss 1.299341\n",
      "batch 168, gen_loss 0.847127,disc_loss 1.300203\n",
      "batch 169, gen_loss 0.866963,disc_loss 1.270305\n",
      "batch 170, gen_loss 0.859802,disc_loss 1.230408\n",
      "batch 171, gen_loss 0.864072,disc_loss 1.256654\n",
      "batch 172, gen_loss 0.876393,disc_loss 1.206811\n",
      "batch 173, gen_loss 0.934665,disc_loss 1.243850\n",
      "batch 174, gen_loss 0.900420,disc_loss 1.235370\n",
      "batch 175, gen_loss 0.882627,disc_loss 1.235501\n",
      "batch 176, gen_loss 0.941136,disc_loss 1.208300\n",
      "batch 177, gen_loss 0.919995,disc_loss 1.233010\n",
      "batch 178, gen_loss 0.867090,disc_loss 1.302637\n",
      "batch 179, gen_loss 0.888353,disc_loss 1.212341\n",
      "batch 180, gen_loss 0.864997,disc_loss 1.249742\n",
      "batch 181, gen_loss 0.923397,disc_loss 1.195498\n",
      "batch 182, gen_loss 0.946571,disc_loss 1.197112\n",
      "batch 183, gen_loss 0.891403,disc_loss 1.272981\n",
      "batch 184, gen_loss 0.898772,disc_loss 1.234767\n",
      "batch 185, gen_loss 0.918528,disc_loss 1.211841\n",
      "batch 186, gen_loss 0.868087,disc_loss 1.252706\n",
      "batch 187, gen_loss 0.937648,disc_loss 1.184742\n",
      "batch 188, gen_loss 0.938319,disc_loss 1.234165\n",
      "batch 189, gen_loss 0.965753,disc_loss 1.171008\n",
      "batch 190, gen_loss 0.924818,disc_loss 1.192948\n",
      "batch 191, gen_loss 0.913954,disc_loss 1.281529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 192, gen_loss 0.956629,disc_loss 1.237626\n",
      "batch 193, gen_loss 0.853126,disc_loss 1.296063\n",
      "batch 194, gen_loss 0.899543,disc_loss 1.247212\n",
      "batch 195, gen_loss 0.910011,disc_loss 1.264039\n",
      "batch 196, gen_loss 0.906716,disc_loss 1.284000\n",
      "batch 197, gen_loss 0.882779,disc_loss 1.299648\n",
      "batch 198, gen_loss 0.867287,disc_loss 1.288237\n",
      "batch 199, gen_loss 0.852247,disc_loss 1.325482\n",
      "batch 200, gen_loss 0.818020,disc_loss 1.345433\n",
      "batch 201, gen_loss 0.869713,disc_loss 1.389812\n",
      "batch 202, gen_loss 0.879076,disc_loss 1.393283\n",
      "batch 203, gen_loss 0.860095,disc_loss 1.384343\n",
      "batch 204, gen_loss 0.830042,disc_loss 1.413499\n",
      "batch 205, gen_loss 0.858864,disc_loss 1.350356\n",
      "batch 206, gen_loss 0.815758,disc_loss 1.391145\n",
      "batch 207, gen_loss 0.778929,disc_loss 1.422919\n",
      "batch 208, gen_loss 0.804575,disc_loss 1.389665\n",
      "batch 209, gen_loss 0.862721,disc_loss 1.420759\n",
      "batch 210, gen_loss 0.828111,disc_loss 1.455351\n",
      "batch 211, gen_loss 0.791199,disc_loss 1.484435\n",
      "batch 212, gen_loss 0.768558,disc_loss 1.519191\n",
      "batch 213, gen_loss 0.769634,disc_loss 1.494136\n",
      "batch 214, gen_loss 0.761696,disc_loss 1.438067\n",
      "batch 215, gen_loss 0.787763,disc_loss 1.454642\n",
      "batch 216, gen_loss 0.808113,disc_loss 1.469554\n",
      "batch 217, gen_loss 0.835897,disc_loss 1.455064\n",
      "batch 218, gen_loss 0.825460,disc_loss 1.468430\n",
      "batch 219, gen_loss 0.820524,disc_loss 1.505244\n",
      "batch 220, gen_loss 0.779909,disc_loss 1.444995\n",
      "batch 221, gen_loss 0.708218,disc_loss 1.454053\n",
      "batch 222, gen_loss 0.759632,disc_loss 1.385269\n",
      "batch 223, gen_loss 0.806325,disc_loss 1.487049\n",
      "batch 224, gen_loss 0.884474,disc_loss 1.372248\n",
      "batch 225, gen_loss 0.875763,disc_loss 1.366304\n",
      "batch 226, gen_loss 0.847436,disc_loss 1.380458\n",
      "batch 227, gen_loss 0.800676,disc_loss 1.307446\n",
      "batch 228, gen_loss 0.789254,disc_loss 1.340580\n",
      "batch 229, gen_loss 0.846665,disc_loss 1.292798\n",
      "batch 230, gen_loss 0.847383,disc_loss 1.264564\n",
      "batch 231, gen_loss 0.943696,disc_loss 1.223127\n",
      "batch 232, gen_loss 1.002633,disc_loss 1.204187\n",
      "batch 233, gen_loss 0.943142,disc_loss 1.202412\n",
      "batch 234, gen_loss 0.911232,disc_loss 1.163267\n",
      "batch 0, gen_loss 0.874818,disc_loss 1.183851\n",
      "batch 1, gen_loss 0.879744,disc_loss 1.144563\n",
      "batch 2, gen_loss 0.940484,disc_loss 1.118662\n",
      "batch 3, gen_loss 0.974686,disc_loss 1.129006\n",
      "batch 4, gen_loss 1.021481,disc_loss 1.094651\n",
      "batch 5, gen_loss 0.996999,disc_loss 1.105339\n",
      "batch 6, gen_loss 1.011086,disc_loss 1.083902\n",
      "batch 7, gen_loss 1.000731,disc_loss 1.077283\n",
      "batch 8, gen_loss 0.996753,disc_loss 1.071361\n",
      "batch 9, gen_loss 0.968570,disc_loss 1.089605\n",
      "batch 10, gen_loss 1.009725,disc_loss 1.021354\n",
      "batch 11, gen_loss 1.011377,disc_loss 1.041417\n",
      "batch 12, gen_loss 1.032354,disc_loss 1.059255\n",
      "batch 13, gen_loss 1.026654,disc_loss 1.052202\n",
      "batch 14, gen_loss 1.026672,disc_loss 1.020983\n",
      "batch 15, gen_loss 1.063024,disc_loss 0.987901\n",
      "batch 16, gen_loss 1.057022,disc_loss 1.016483\n",
      "batch 17, gen_loss 1.063849,disc_loss 1.035012\n",
      "batch 18, gen_loss 0.999254,disc_loss 1.036958\n",
      "batch 19, gen_loss 1.010461,disc_loss 1.033507\n",
      "batch 20, gen_loss 1.027241,disc_loss 0.997920\n",
      "batch 21, gen_loss 1.081013,disc_loss 1.014392\n",
      "batch 22, gen_loss 1.080545,disc_loss 1.031093\n",
      "batch 23, gen_loss 1.075617,disc_loss 0.992403\n",
      "batch 24, gen_loss 1.006946,disc_loss 1.018661\n",
      "batch 25, gen_loss 1.009063,disc_loss 1.007514\n",
      "batch 26, gen_loss 1.022236,disc_loss 1.023307\n",
      "batch 27, gen_loss 1.066064,disc_loss 1.023362\n",
      "batch 28, gen_loss 1.099558,disc_loss 1.039905\n",
      "batch 29, gen_loss 1.083132,disc_loss 1.054461\n",
      "batch 30, gen_loss 0.989690,disc_loss 1.043064\n",
      "batch 31, gen_loss 0.997530,disc_loss 1.011615\n",
      "batch 32, gen_loss 1.062849,disc_loss 0.974333\n",
      "batch 33, gen_loss 1.113949,disc_loss 1.040179\n",
      "batch 34, gen_loss 1.108789,disc_loss 1.017225\n",
      "batch 35, gen_loss 1.090353,disc_loss 1.004614\n",
      "batch 36, gen_loss 1.101050,disc_loss 0.987737\n",
      "batch 37, gen_loss 1.020977,disc_loss 1.077679\n",
      "batch 38, gen_loss 1.055422,disc_loss 1.029258\n",
      "batch 39, gen_loss 1.024896,disc_loss 1.006741\n",
      "batch 40, gen_loss 1.039512,disc_loss 0.994660\n",
      "batch 41, gen_loss 1.073252,disc_loss 1.014615\n",
      "batch 42, gen_loss 1.056361,disc_loss 1.036972\n",
      "batch 43, gen_loss 1.071571,disc_loss 1.006182\n",
      "batch 44, gen_loss 1.123701,disc_loss 1.031665\n",
      "batch 45, gen_loss 1.116709,disc_loss 1.021187\n",
      "batch 46, gen_loss 1.027510,disc_loss 1.044498\n",
      "batch 47, gen_loss 1.037328,disc_loss 1.033924\n",
      "batch 48, gen_loss 1.027440,disc_loss 0.997054\n",
      "batch 49, gen_loss 1.040698,disc_loss 0.987276\n",
      "batch 50, gen_loss 1.084040,disc_loss 1.038157\n",
      "batch 51, gen_loss 1.093348,disc_loss 1.035627\n",
      "batch 52, gen_loss 1.137940,disc_loss 0.984960\n",
      "batch 53, gen_loss 1.065725,disc_loss 1.018013\n",
      "batch 54, gen_loss 1.048155,disc_loss 1.050239\n",
      "batch 55, gen_loss 1.015308,disc_loss 1.085208\n",
      "batch 56, gen_loss 0.999063,disc_loss 1.037127\n",
      "batch 57, gen_loss 1.047455,disc_loss 1.060786\n",
      "batch 58, gen_loss 1.072236,disc_loss 0.974419\n",
      "batch 59, gen_loss 1.077767,disc_loss 1.034021\n",
      "batch 60, gen_loss 1.119589,disc_loss 0.982415\n",
      "batch 61, gen_loss 1.133844,disc_loss 1.032246\n",
      "batch 62, gen_loss 1.051475,disc_loss 1.007591\n",
      "batch 63, gen_loss 1.095215,disc_loss 1.033789\n",
      "batch 64, gen_loss 1.042681,disc_loss 1.068022\n",
      "batch 65, gen_loss 1.027875,disc_loss 1.045174\n",
      "batch 66, gen_loss 1.034787,disc_loss 1.032948\n",
      "batch 67, gen_loss 1.076296,disc_loss 1.000259\n",
      "batch 68, gen_loss 1.117114,disc_loss 1.050658\n",
      "batch 69, gen_loss 1.132701,disc_loss 1.033563\n",
      "batch 70, gen_loss 1.142733,disc_loss 1.018196\n",
      "batch 71, gen_loss 1.055439,disc_loss 1.057022\n",
      "batch 72, gen_loss 1.028085,disc_loss 1.089756\n",
      "batch 73, gen_loss 1.002369,disc_loss 1.012657\n",
      "batch 74, gen_loss 0.988411,disc_loss 1.048530\n",
      "batch 75, gen_loss 1.128087,disc_loss 1.099248\n",
      "batch 76, gen_loss 1.071937,disc_loss 1.072432\n",
      "batch 77, gen_loss 1.047210,disc_loss 1.068999\n",
      "batch 78, gen_loss 1.114216,disc_loss 1.094011\n",
      "batch 79, gen_loss 0.996565,disc_loss 1.099292\n",
      "batch 80, gen_loss 1.043183,disc_loss 1.130641\n",
      "batch 81, gen_loss 0.952265,disc_loss 1.145756\n",
      "batch 82, gen_loss 0.974682,disc_loss 1.112487\n",
      "batch 83, gen_loss 0.960554,disc_loss 1.193420\n",
      "batch 84, gen_loss 0.954984,disc_loss 1.166328\n",
      "batch 85, gen_loss 0.969980,disc_loss 1.159684\n",
      "batch 86, gen_loss 0.971033,disc_loss 1.187001\n",
      "batch 87, gen_loss 0.994012,disc_loss 1.242870\n",
      "batch 88, gen_loss 0.917264,disc_loss 1.185559\n",
      "batch 89, gen_loss 0.879836,disc_loss 1.277177\n",
      "batch 90, gen_loss 0.924262,disc_loss 1.251140\n",
      "batch 91, gen_loss 0.934190,disc_loss 1.209703\n",
      "batch 92, gen_loss 0.905838,disc_loss 1.236028\n",
      "batch 93, gen_loss 0.940830,disc_loss 1.258852\n",
      "batch 94, gen_loss 0.921238,disc_loss 1.358997\n",
      "batch 95, gen_loss 0.898004,disc_loss 1.277051\n",
      "batch 96, gen_loss 0.849688,disc_loss 1.300175\n",
      "batch 97, gen_loss 0.851781,disc_loss 1.243111\n",
      "batch 98, gen_loss 0.870261,disc_loss 1.336974\n",
      "batch 99, gen_loss 0.833204,disc_loss 1.340173\n",
      "batch 100, gen_loss 0.902735,disc_loss 1.369171\n",
      "batch 101, gen_loss 0.856793,disc_loss 1.326983\n",
      "batch 102, gen_loss 0.868088,disc_loss 1.313977\n",
      "batch 103, gen_loss 0.883523,disc_loss 1.320705\n",
      "batch 104, gen_loss 0.891603,disc_loss 1.344147\n",
      "batch 105, gen_loss 0.863711,disc_loss 1.379985\n",
      "batch 106, gen_loss 0.796480,disc_loss 1.362324\n",
      "batch 107, gen_loss 0.792377,disc_loss 1.357483\n",
      "batch 108, gen_loss 0.813444,disc_loss 1.349095\n",
      "batch 109, gen_loss 0.837755,disc_loss 1.378470\n",
      "batch 110, gen_loss 0.842398,disc_loss 1.346399\n",
      "batch 111, gen_loss 0.848098,disc_loss 1.333901\n",
      "batch 112, gen_loss 0.864092,disc_loss 1.358573\n",
      "batch 113, gen_loss 0.848137,disc_loss 1.312866\n",
      "batch 114, gen_loss 0.813044,disc_loss 1.336254\n",
      "batch 115, gen_loss 0.838058,disc_loss 1.249755\n",
      "batch 116, gen_loss 0.897389,disc_loss 1.291020\n",
      "batch 117, gen_loss 0.863690,disc_loss 1.358146\n",
      "batch 118, gen_loss 0.819326,disc_loss 1.311457\n",
      "batch 119, gen_loss 0.875584,disc_loss 1.300167\n",
      "batch 120, gen_loss 0.911589,disc_loss 1.281377\n",
      "batch 121, gen_loss 0.902636,disc_loss 1.271449\n",
      "batch 122, gen_loss 0.908794,disc_loss 1.268345\n",
      "batch 123, gen_loss 0.823011,disc_loss 1.332744\n",
      "batch 124, gen_loss 0.814724,disc_loss 1.328194\n",
      "batch 125, gen_loss 0.845682,disc_loss 1.307151\n",
      "batch 126, gen_loss 0.890831,disc_loss 1.312251\n",
      "batch 127, gen_loss 0.894916,disc_loss 1.312189\n",
      "batch 128, gen_loss 0.903865,disc_loss 1.336613\n",
      "batch 129, gen_loss 0.905650,disc_loss 1.280435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 130, gen_loss 0.840913,disc_loss 1.229862\n",
      "batch 131, gen_loss 0.833778,disc_loss 1.278280\n",
      "batch 132, gen_loss 0.893176,disc_loss 1.289581\n",
      "batch 133, gen_loss 0.926545,disc_loss 1.276267\n",
      "batch 134, gen_loss 0.925285,disc_loss 1.300690\n",
      "batch 135, gen_loss 0.938851,disc_loss 1.261517\n",
      "batch 136, gen_loss 0.965005,disc_loss 1.221808\n",
      "batch 137, gen_loss 0.957975,disc_loss 1.236547\n",
      "batch 138, gen_loss 0.909174,disc_loss 1.230746\n",
      "batch 139, gen_loss 0.901992,disc_loss 1.249574\n",
      "batch 140, gen_loss 0.832329,disc_loss 1.282944\n",
      "batch 141, gen_loss 0.877921,disc_loss 1.260942\n",
      "batch 142, gen_loss 0.967272,disc_loss 1.237303\n",
      "batch 143, gen_loss 1.001211,disc_loss 1.277022\n",
      "batch 144, gen_loss 0.955003,disc_loss 1.226815\n",
      "batch 145, gen_loss 0.927795,disc_loss 1.206858\n",
      "batch 146, gen_loss 0.909392,disc_loss 1.231449\n",
      "batch 147, gen_loss 0.866830,disc_loss 1.200058\n",
      "batch 148, gen_loss 0.955791,disc_loss 1.240663\n",
      "batch 149, gen_loss 0.979158,disc_loss 1.176001\n",
      "batch 150, gen_loss 0.967858,disc_loss 1.193367\n",
      "batch 151, gen_loss 1.013701,disc_loss 1.161187\n",
      "batch 152, gen_loss 0.964108,disc_loss 1.181610\n",
      "batch 153, gen_loss 0.930782,disc_loss 1.170628\n",
      "batch 154, gen_loss 0.906105,disc_loss 1.166934\n",
      "batch 155, gen_loss 0.940989,disc_loss 1.115378\n",
      "batch 156, gen_loss 0.960697,disc_loss 1.168612\n",
      "batch 157, gen_loss 1.082698,disc_loss 1.121259\n",
      "batch 158, gen_loss 1.048297,disc_loss 1.184645\n",
      "batch 159, gen_loss 1.013021,disc_loss 1.192443\n",
      "batch 160, gen_loss 0.925900,disc_loss 1.134973\n",
      "batch 161, gen_loss 0.889309,disc_loss 1.172983\n",
      "batch 162, gen_loss 0.872113,disc_loss 1.139520\n",
      "batch 163, gen_loss 0.962144,disc_loss 1.153350\n",
      "batch 164, gen_loss 1.045884,disc_loss 1.098904\n",
      "batch 165, gen_loss 1.027258,disc_loss 1.142975\n",
      "batch 166, gen_loss 1.027630,disc_loss 1.130844\n",
      "batch 167, gen_loss 1.014326,disc_loss 1.166452\n",
      "batch 168, gen_loss 0.907208,disc_loss 1.249720\n",
      "batch 169, gen_loss 0.936442,disc_loss 1.125918\n",
      "batch 170, gen_loss 0.961836,disc_loss 1.150613\n",
      "batch 171, gen_loss 0.997979,disc_loss 1.151670\n",
      "batch 172, gen_loss 1.021442,disc_loss 1.110980\n",
      "batch 173, gen_loss 0.965525,disc_loss 1.161546\n",
      "batch 174, gen_loss 1.031338,disc_loss 1.120820\n",
      "batch 175, gen_loss 1.025746,disc_loss 1.077013\n",
      "batch 176, gen_loss 0.989182,disc_loss 1.145837\n",
      "batch 177, gen_loss 0.997828,disc_loss 1.054759\n",
      "batch 178, gen_loss 1.018519,disc_loss 1.118312\n",
      "batch 179, gen_loss 1.048866,disc_loss 1.064566\n",
      "batch 180, gen_loss 0.999978,disc_loss 1.098559\n",
      "batch 181, gen_loss 1.047524,disc_loss 1.111789\n",
      "batch 182, gen_loss 1.038510,disc_loss 1.108269\n",
      "batch 183, gen_loss 1.013015,disc_loss 1.080630\n",
      "batch 184, gen_loss 0.971623,disc_loss 1.089854\n",
      "batch 185, gen_loss 1.058289,disc_loss 1.026727\n",
      "batch 186, gen_loss 1.044922,disc_loss 1.089294\n",
      "batch 187, gen_loss 1.020740,disc_loss 1.073031\n",
      "batch 188, gen_loss 1.055374,disc_loss 1.082256\n",
      "batch 189, gen_loss 1.061241,disc_loss 1.071547\n",
      "batch 190, gen_loss 0.999542,disc_loss 1.096044\n",
      "batch 191, gen_loss 1.031639,disc_loss 1.077598\n",
      "batch 192, gen_loss 1.048788,disc_loss 1.078461\n",
      "batch 193, gen_loss 0.997549,disc_loss 1.082560\n",
      "batch 194, gen_loss 1.062711,disc_loss 1.081311\n",
      "batch 195, gen_loss 1.023836,disc_loss 1.100050\n",
      "batch 196, gen_loss 1.013779,disc_loss 1.100220\n",
      "batch 197, gen_loss 1.032918,disc_loss 1.074607\n",
      "batch 198, gen_loss 1.056435,disc_loss 1.022929\n",
      "batch 199, gen_loss 1.039671,disc_loss 1.050071\n",
      "batch 200, gen_loss 1.044877,disc_loss 1.067224\n",
      "batch 201, gen_loss 1.027582,disc_loss 1.091083\n",
      "batch 202, gen_loss 1.055667,disc_loss 1.031438\n",
      "batch 203, gen_loss 1.082683,disc_loss 1.059239\n",
      "batch 204, gen_loss 1.103190,disc_loss 1.081686\n",
      "batch 205, gen_loss 1.035146,disc_loss 1.039421\n",
      "batch 206, gen_loss 0.987577,disc_loss 1.084840\n",
      "batch 207, gen_loss 0.960656,disc_loss 1.067454\n",
      "batch 208, gen_loss 1.048849,disc_loss 1.076938\n",
      "batch 209, gen_loss 1.098151,disc_loss 1.066054\n",
      "batch 210, gen_loss 1.071139,disc_loss 1.073540\n",
      "batch 211, gen_loss 1.046412,disc_loss 1.045548\n",
      "batch 212, gen_loss 1.014315,disc_loss 1.113576\n",
      "batch 213, gen_loss 0.982875,disc_loss 1.062358\n",
      "batch 214, gen_loss 0.992694,disc_loss 1.129844\n",
      "batch 215, gen_loss 1.037499,disc_loss 1.128777\n",
      "batch 216, gen_loss 1.041026,disc_loss 1.090406\n",
      "batch 217, gen_loss 0.992288,disc_loss 1.106710\n",
      "batch 218, gen_loss 0.967812,disc_loss 1.163182\n",
      "batch 219, gen_loss 0.953938,disc_loss 1.169849\n",
      "batch 220, gen_loss 0.927432,disc_loss 1.159825\n",
      "batch 221, gen_loss 0.977741,disc_loss 1.206925\n",
      "batch 222, gen_loss 0.975616,disc_loss 1.167792\n",
      "batch 223, gen_loss 1.024055,disc_loss 1.126131\n",
      "batch 224, gen_loss 0.945585,disc_loss 1.195742\n",
      "batch 225, gen_loss 0.904818,disc_loss 1.240312\n",
      "batch 226, gen_loss 0.881380,disc_loss 1.212905\n",
      "batch 227, gen_loss 0.879062,disc_loss 1.279730\n",
      "batch 228, gen_loss 0.925436,disc_loss 1.238964\n",
      "batch 229, gen_loss 0.908654,disc_loss 1.290480\n",
      "batch 230, gen_loss 0.961493,disc_loss 1.217219\n",
      "batch 231, gen_loss 0.918179,disc_loss 1.251596\n",
      "batch 232, gen_loss 0.861163,disc_loss 1.275985\n",
      "batch 233, gen_loss 0.879081,disc_loss 1.265625\n",
      "batch 234, gen_loss 0.823236,disc_loss 1.282269\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x9901f36688>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
